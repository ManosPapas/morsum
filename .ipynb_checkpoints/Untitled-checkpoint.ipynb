{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy.linalg import eig\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (18249, 13)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"avocado.csv\", index_col=0)\n",
    "\n",
    "print(\"Dimensions: \" + str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "def dummy_df(df, todummy_list, drop_=True):\n",
    "    for x in todummy_list:\n",
    "        dummies = pd.get_dummies(df[x], prefix=x, dummy_na=False, drop_first=drop_)\n",
    "        \n",
    "        df = df.drop(x,1)\n",
    "        \n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make region variable dummy variable\n",
    "df = dummy_df(data, ['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop year we have date.\n",
    "df = df.drop(['year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map type to 0 and 1. \n",
    "df['type'] = data['type'].map({'conventional': 0, 'organic': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date from string to date object.\n",
    "df['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "df['Date']=df['Date'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>...</th>\n",
       "      <th>region_SouthCarolina</th>\n",
       "      <th>region_SouthCentral</th>\n",
       "      <th>region_Southeast</th>\n",
       "      <th>region_Spokane</th>\n",
       "      <th>region_StLouis</th>\n",
       "      <th>region_Syracuse</th>\n",
       "      <th>region_Tampa</th>\n",
       "      <th>region_TotalUS</th>\n",
       "      <th>region_West</th>\n",
       "      <th>region_WestTexNewMexico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>735959</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>735952</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>735945</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>735938</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>735931</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  AveragePrice  Total Volume     4046       4225    4770  Total Bags  \\\n",
       "0  735959          1.33      64236.62  1036.74   54454.85   48.16     8696.87   \n",
       "1  735952          1.35      54876.98   674.28   44638.81   58.33     9505.56   \n",
       "2  735945          0.93     118220.22   794.70  109149.67  130.50     8145.35   \n",
       "3  735938          1.08      78992.15  1132.00   71976.41   72.58     5811.16   \n",
       "4  735931          1.28      51039.60   941.48   43838.39   75.78     6183.95   \n",
       "\n",
       "   Small Bags  Large Bags  XLarge Bags           ...             \\\n",
       "0     8603.62       93.25          0.0           ...              \n",
       "1     9408.07       97.49          0.0           ...              \n",
       "2     8042.21      103.14          0.0           ...              \n",
       "3     5677.40      133.76          0.0           ...              \n",
       "4     5986.26      197.69          0.0           ...              \n",
       "\n",
       "   region_SouthCarolina  region_SouthCentral  region_Southeast  \\\n",
       "0                     0                    0                 0   \n",
       "1                     0                    0                 0   \n",
       "2                     0                    0                 0   \n",
       "3                     0                    0                 0   \n",
       "4                     0                    0                 0   \n",
       "\n",
       "   region_Spokane  region_StLouis  region_Syracuse  region_Tampa  \\\n",
       "0               0               0                0             0   \n",
       "1               0               0                0             0   \n",
       "2               0               0                0             0   \n",
       "3               0               0                0             0   \n",
       "4               0               0                0             0   \n",
       "\n",
       "   region_TotalUS  region_West  region_WestTexNewMexico  \n",
       "0               0            0                        0  \n",
       "1               0            0                        0  \n",
       "2               0            0                        0  \n",
       "3               0            0                        0  \n",
       "4               0            0                        0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 intialise parameters to find gloabal minimum\n",
    "def initialize_parameters(length):\n",
    "    # weights \n",
    "    w = np.random.rand(1, length)\n",
    "    # bias\n",
    "    b = 0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 define forward propagation\n",
    "def forward_propagation(X,w,b):\n",
    "    # matrix multiplication + bias\n",
    "    z = np.dot(w,X) + b\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "def cost_function(z,y):\n",
    "    # number of columns\n",
    "    col = y.shape[1]\n",
    "    # formula\n",
    "    cf = (1/(2*col))*np.sum(np.square(z-y))\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning the weights of a the error rate (i.e. loss) obtained in the previous epoch \n",
    "def back_propagation(X,y,z):\n",
    "    # number of columns\n",
    "    col = y.shape[1]\n",
    "    dz = (1/col)*(z-y)\n",
    "    dw = np.dot(dz, X.T)\n",
    "    db = np.sum(dz)\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizing a function by following the gradients of the cost functio\n",
    "def gradient_descent_update(w,b,dw,db, learning_rate):\n",
    "    w = w - learning_rate*dw\n",
    "    b = b - learning_rate*db\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model\n",
    "def linear_regression_model(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
    "    lenw = X_train.shape[0]\n",
    "    w,b = initialize_parameters(lenw)\n",
    "    \n",
    "    consts_train = []\n",
    "    m_train = y_train.shape[1]\n",
    "    m_val = y_val.shape[1]\n",
    "    for i in range(1, epochs+1):\n",
    "        z_train = forward_propagation(X_train,w,b)\n",
    "        cost_train = cost_function(z_train, y_train)\n",
    "        dw, db = back_propagation(X_train, y_train, z_train)\n",
    "        w,b = gradient_descent_update(w,b,dw,db,learning_rate)\n",
    "        \n",
    "        if i%10==0:\n",
    "            consts_train.append(cost_train)\n",
    "        MAE_train = (1/m_train)*np.sum(np.abs(z_train-y_train))\n",
    "        \n",
    "        z_val=forward_propagation(X_val, w,b)\n",
    "        cost_val = cost_function(z_val, y_val)\n",
    "        #Mean Absolute Error\n",
    "        MAE_val = (1/m_val)*np.sum(np.abs(z_val-y_val))\n",
    "        # print each epoch.\n",
    "        print('Epochs: '+str(i)+'/'+str(epochs)+\": \")\n",
    "        print('training cost: '+str(cost_train)+' validation cost'+str(cost_val)+\": \")\n",
    "        #Mean Absolute Error\n",
    "        print('training mae: '+str(MAE_train)+' validation mae'+str(MAE_val)+\": \")\n",
    "    # plots to check    \n",
    "    plt.plot(consts_train)\n",
    "    plt.xlabel('Iterations per tens')\n",
    "    plt.ylabel(\"training cost\")\n",
    "    plt.title(\"learning rate\" + str(learning_rate))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (df - df.mean())/(df.max() - df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>...</th>\n",
       "      <th>region_SouthCarolina</th>\n",
       "      <th>region_SouthCentral</th>\n",
       "      <th>region_Southeast</th>\n",
       "      <th>region_Spokane</th>\n",
       "      <th>region_StLouis</th>\n",
       "      <th>region_Syracuse</th>\n",
       "      <th>region_Tampa</th>\n",
       "      <th>region_TotalUS</th>\n",
       "      <th>region_West</th>\n",
       "      <th>region_WestTexNewMexico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.196411</td>\n",
       "      <td>-0.027039</td>\n",
       "      <td>-0.012581</td>\n",
       "      <td>-0.012838</td>\n",
       "      <td>-0.011758</td>\n",
       "      <td>-0.008950</td>\n",
       "      <td>-0.011921</td>\n",
       "      <td>-0.012969</td>\n",
       "      <td>-0.009485</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.202364</td>\n",
       "      <td>-0.019921</td>\n",
       "      <td>-0.012731</td>\n",
       "      <td>-0.012853</td>\n",
       "      <td>-0.012238</td>\n",
       "      <td>-0.008946</td>\n",
       "      <td>-0.011879</td>\n",
       "      <td>-0.012909</td>\n",
       "      <td>-0.009484</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.208316</td>\n",
       "      <td>-0.169387</td>\n",
       "      <td>-0.011718</td>\n",
       "      <td>-0.012848</td>\n",
       "      <td>-0.009086</td>\n",
       "      <td>-0.008918</td>\n",
       "      <td>-0.011949</td>\n",
       "      <td>-0.013011</td>\n",
       "      <td>-0.009483</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.214268</td>\n",
       "      <td>-0.116007</td>\n",
       "      <td>-0.012345</td>\n",
       "      <td>-0.012833</td>\n",
       "      <td>-0.010902</td>\n",
       "      <td>-0.008941</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>-0.013188</td>\n",
       "      <td>-0.009478</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.220221</td>\n",
       "      <td>-0.044832</td>\n",
       "      <td>-0.012793</td>\n",
       "      <td>-0.012842</td>\n",
       "      <td>-0.012277</td>\n",
       "      <td>-0.008940</td>\n",
       "      <td>-0.012050</td>\n",
       "      <td>-0.013165</td>\n",
       "      <td>-0.009467</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.018357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  AveragePrice  Total Volume      4046      4225      4770  \\\n",
       "0 -0.196411     -0.027039     -0.012581 -0.012838 -0.011758 -0.008950   \n",
       "1 -0.202364     -0.019921     -0.012731 -0.012853 -0.012238 -0.008946   \n",
       "2 -0.208316     -0.169387     -0.011718 -0.012848 -0.009086 -0.008918   \n",
       "3 -0.214268     -0.116007     -0.012345 -0.012833 -0.010902 -0.008941   \n",
       "4 -0.220221     -0.044832     -0.012793 -0.012842 -0.012277 -0.008940   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags           ...             \\\n",
       "0   -0.011921   -0.012969   -0.009485    -0.005631           ...              \n",
       "1   -0.011879   -0.012909   -0.009484    -0.005631           ...              \n",
       "2   -0.011949   -0.013011   -0.009483    -0.005631           ...              \n",
       "3   -0.012070   -0.013188   -0.009478    -0.005631           ...              \n",
       "4   -0.012050   -0.013165   -0.009467    -0.005631           ...              \n",
       "\n",
       "   region_SouthCarolina  region_SouthCentral  region_Southeast  \\\n",
       "0             -0.018522            -0.018522         -0.018522   \n",
       "1             -0.018522            -0.018522         -0.018522   \n",
       "2             -0.018522            -0.018522         -0.018522   \n",
       "3             -0.018522            -0.018522         -0.018522   \n",
       "4             -0.018522            -0.018522         -0.018522   \n",
       "\n",
       "   region_Spokane  region_StLouis  region_Syracuse  region_Tampa  \\\n",
       "0       -0.018522       -0.018522        -0.018522     -0.018522   \n",
       "1       -0.018522       -0.018522        -0.018522     -0.018522   \n",
       "2       -0.018522       -0.018522        -0.018522     -0.018522   \n",
       "3       -0.018522       -0.018522        -0.018522     -0.018522   \n",
       "4       -0.018522       -0.018522        -0.018522     -0.018522   \n",
       "\n",
       "   region_TotalUS  region_West  region_WestTexNewMexico  \n",
       "0       -0.018522    -0.018522                -0.018357  \n",
       "1       -0.018522    -0.018522                -0.018357  \n",
       "2       -0.018522    -0.018522                -0.018357  \n",
       "3       -0.018522    -0.018522                -0.018357  \n",
       "4       -0.018522    -0.018522                -0.018357  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove the variable that we want to predict\n",
    "X = X.drop(['AveragePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y = data['AveragePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to make the comparison fair.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.array([y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1/500: \n",
      "training cost: 1.1068420262899383 validation cost0.467987247190367: \n",
      "training mae: 1.4184323907038707 validation mae0.8687243710067304: \n",
      "Epochs: 2/500: \n",
      "training cost: 0.471846201841428 validation cost0.23979761516085105: \n",
      "training mae: 0.8712075578687349 validation mae0.5749818553132949: \n",
      "Epochs: 3/500: \n",
      "training cost: 0.24242077538734425 validation cost0.15710025240206432: \n",
      "training mae: 0.5750409249712525 validation mae0.4444624168099445: \n",
      "Epochs: 4/500: \n",
      "training cost: 0.15901311287811573 validation cost0.12668222354846725: \n",
      "training mae: 0.44245896211478297 validation mae0.3930526366357989: \n",
      "Epochs: 5/500: \n",
      "training cost: 0.1281869182027665 validation cost0.11503414541404834: \n",
      "training mae: 0.39177925910659395 validation mae0.37326922872657636: \n",
      "Epochs: 6/500: \n",
      "training cost: 0.11630566469366543 validation cost0.1101199455016619: \n",
      "training mae: 0.3725339078886552 validation mae0.36465884308995206: \n",
      "Epochs: 7/500: \n",
      "training cost: 0.11126003009822988 validation cost0.10762240867239098: \n",
      "training mae: 0.36430494855253104 validation mae0.3603030059595179: \n",
      "Epochs: 8/500: \n",
      "training cost: 0.10869026854777339 validation cost0.10599640596804193: \n",
      "training mae: 0.3601461063109365 validation mae0.3575756243953832: \n",
      "Epochs: 9/500: \n",
      "training cost: 0.1070264359286024 validation cost0.10469085195717154: \n",
      "training mae: 0.3574037284844972 validation mae0.35533406641915416: \n",
      "Epochs: 10/500: \n",
      "training cost: 0.10570292716859489 validation cost0.10351023594554318: \n",
      "training mae: 0.3551999762647866 validation mae0.35330879986340213: \n",
      "Epochs: 11/500: \n",
      "training cost: 0.10451572535292249 validation cost0.10238572337564827: \n",
      "training mae: 0.35321348532089447 validation mae0.35138550959581955: \n",
      "Epochs: 12/500: \n",
      "training cost: 0.1033910133825637 validation cost0.1012933085503904: \n",
      "training mae: 0.3513263340048497 validation mae0.3495146455482908: \n",
      "Epochs: 13/500: \n",
      "training cost: 0.10230187189851053 validation cost0.10022467550893203: \n",
      "training mae: 0.3494914582236765 validation mae0.34768095231579726: \n",
      "Epochs: 14/500: \n",
      "training cost: 0.1012382872886371 validation cost0.09917689885287896: \n",
      "training mae: 0.347688678793126 validation mae0.3458767887092634: \n",
      "Epochs: 15/500: \n",
      "training cost: 0.10019635142497156 validation cost0.09814884773903194: \n",
      "training mae: 0.3459139272135994 validation mae0.3441017100118306: \n",
      "Epochs: 16/500: \n",
      "training cost: 0.09917437082531251 validation cost0.0971399565000297: \n",
      "training mae: 0.3441616637057742 validation mae0.3423527728852736: \n",
      "Epochs: 17/500: \n",
      "training cost: 0.0981714636478836 validation cost0.0961498199466936: \n",
      "training mae: 0.342429072099564 validation mae0.3406284254596775: \n",
      "Epochs: 18/500: \n",
      "training cost: 0.0971870527039901 validation cost0.09517806954264617: \n",
      "training mae: 0.3407176899046174 validation mae0.3389287158375848: \n",
      "Epochs: 19/500: \n",
      "training cost: 0.09622068137463116 validation cost0.09422434131939394: \n",
      "training mae: 0.33902779854240334 validation mae0.33724927215093203: \n",
      "Epochs: 20/500: \n",
      "training cost: 0.09527194605139397 validation cost0.09328827134784658: \n",
      "training mae: 0.3373561759836007 validation mae0.3355932660468712: \n",
      "Epochs: 21/500: \n",
      "training cost: 0.09434047075406903 validation cost0.09236949795300883: \n",
      "training mae: 0.3357030483441536 validation mae0.33395658302521947: \n",
      "Epochs: 22/500: \n",
      "training cost: 0.09342589711744598 validation cost0.09146766452399371: \n",
      "training mae: 0.3340709184204842 validation mae0.3323383201437496: \n",
      "Epochs: 23/500: \n",
      "training cost: 0.09252788006179447 validation cost0.09058242149304799: \n",
      "training mae: 0.33246031161550593 validation mae0.3307393407146483: \n",
      "Epochs: 24/500: \n",
      "training cost: 0.0916460856319375 validation cost0.0897134274288259: \n",
      "training mae: 0.330869407971405 validation mae0.329161873132034: \n",
      "Epochs: 25/500: \n",
      "training cost: 0.09078018971650376 validation cost0.08886034949009755: \n",
      "training mae: 0.3292973098484294 validation mae0.32760667079295824: \n",
      "Epochs: 26/500: \n",
      "training cost: 0.08992987716490577 validation cost0.088022863481384: \n",
      "training mae: 0.32774538734652225 validation mae0.3260703227651006: \n",
      "Epochs: 27/500: \n",
      "training cost: 0.08909484111327305 validation cost0.08720065368425645: \n",
      "training mae: 0.3262127687921066 validation mae0.32455449997711744: \n",
      "Epochs: 28/500: \n",
      "training cost: 0.08827478243916338 validation cost0.08639341257520357: \n",
      "training mae: 0.3246980977305392 validation mae0.3230636049178163: \n",
      "Epochs: 29/500: \n",
      "training cost: 0.08746940930629102 validation cost0.08560084049613689: \n",
      "training mae: 0.32320143102000676 validation mae0.3215912582833902: \n",
      "Epochs: 30/500: \n",
      "training cost: 0.08667843677730129 validation cost0.08482264531474813: \n",
      "training mae: 0.32172406670477655 validation mae0.3201379377730227: \n",
      "Epochs: 31/500: \n",
      "training cost: 0.08590158648018727 validation cost0.08405854209437486: \n",
      "training mae: 0.3202636245791891 validation mae0.31870202165429856: \n",
      "Epochs: 32/500: \n",
      "training cost: 0.08513858631789997 validation cost0.08330825278275932: \n",
      "training mae: 0.31882034561326417 validation mae0.31728600108431476: \n",
      "Epochs: 33/500: \n",
      "training cost: 0.08438917021312523 validation cost0.0825715059232862: \n",
      "training mae: 0.3173964178296846 validation mae0.3158867484141136: \n",
      "Epochs: 34/500: \n",
      "training cost: 0.08365307788187847 validation cost0.0818480363891535: \n",
      "training mae: 0.3159884575679592 validation mae0.31450385105577283: \n",
      "Epochs: 35/500: \n",
      "training cost: 0.08293005463082687 validation cost0.08113758513934498: \n",
      "training mae: 0.31459805405119523 validation mae0.3131377290008455: \n",
      "Epochs: 36/500: \n",
      "training cost: 0.08221985117423007 validation cost0.08043989899456536: \n",
      "training mae: 0.313225413469232 validation mae0.311791261333525: \n",
      "Epochs: 37/500: \n",
      "training cost: 0.08152222346717093 validation cost0.07975473043107363: \n",
      "training mae: 0.3118717254432113 validation mae0.31046047612409283: \n",
      "Epochs: 38/500: \n",
      "training cost: 0.08083693255237745 validation cost0.07908183739037547: \n",
      "training mae: 0.3105359351344277 validation mae0.3091439629414191: \n",
      "Epochs: 39/500: \n",
      "training cost: 0.08016374441844222 validation cost0.07842098310288449: \n",
      "training mae: 0.3092157610230964 validation mae0.30784394845122687: \n",
      "Epochs: 40/500: \n",
      "training cost: 0.07950242986765622 validation cost0.07777193592385884: \n",
      "training mae: 0.3079121646210625 validation mae0.30656099963438704: \n",
      "Epochs: 41/500: \n",
      "training cost: 0.07885276439200478 validation cost0.07713446918012697: \n",
      "training mae: 0.3066245354555481 validation mae0.3052939599282516: \n",
      "Epochs: 42/500: \n",
      "training cost: 0.0782145280561422 validation cost0.07650836102631475: \n",
      "training mae: 0.30535415164148916 validation mae0.3040410540606744: \n",
      "Epochs: 43/500: \n",
      "training cost: 0.07758750538637882 validation cost0.07589339430946518: \n",
      "training mae: 0.30409889339419766 validation mae0.30280085923040895: \n",
      "Epochs: 44/500: \n",
      "training cost: 0.07697148526489023 validation cost0.0752893564410999: \n",
      "training mae: 0.30286028230818807 validation mae0.30157448549134375: \n",
      "Epochs: 45/500: \n",
      "training cost: 0.07636626082850104 validation cost0.07469603927590947: \n",
      "training mae: 0.3016391288381171 validation mae0.3003615370395733: \n",
      "Epochs: 46/500: \n",
      "training cost: 0.07577162937151162 validation cost0.07411323899637508: \n",
      "training mae: 0.3004328190445149 validation mae0.2991621202604797: \n",
      "Epochs: 47/500: \n",
      "training cost: 0.07518739225212948 validation cost0.07354075600272468: \n",
      "training mae: 0.2992412886756912 validation mae0.29797741353404855: \n",
      "Epochs: 48/500: \n",
      "training cost: 0.07461335480214339 validation cost0.07297839480771076: \n",
      "training mae: 0.2980656730842514 validation mae0.29680858033536534: \n",
      "Epochs: 49/500: \n",
      "training cost: 0.07404932623953972 validation cost0.07242596393576736: \n",
      "training mae: 0.2969064625400927 validation mae0.29565670957967916: \n",
      "Epochs: 50/500: \n",
      "training cost: 0.07349511958381122 validation cost0.07188327582616495: \n",
      "training mae: 0.29576215061853967 validation mae0.294521761114139: \n",
      "Epochs: 51/500: \n",
      "training cost: 0.07295055157374825 validation cost0.07135014673983188: \n",
      "training mae: 0.2946324656366764 validation mae0.2933997989271062: \n",
      "Epochs: 52/500: \n",
      "training cost: 0.07241544258753653 validation cost0.07082639666955394: \n",
      "training mae: 0.29351703844695054 validation mae0.29229080445713124: \n",
      "Epochs: 53/500: \n",
      "training cost: 0.07188961656501196 validation cost0.07031184925330079: \n",
      "training mae: 0.29241563000538096 validation mae0.2911934253629084: \n",
      "Epochs: 54/500: \n",
      "training cost: 0.07137290093194469 validation cost0.06980633169045768: \n",
      "training mae: 0.2913273514618062 validation mae0.2901101469152115: \n",
      "Epochs: 55/500: \n",
      "training cost: 0.0708651265262437 validation cost0.06930967466076805: \n",
      "training mae: 0.2902525034653675 validation mae0.28903907165412057: \n",
      "Epochs: 56/500: \n",
      "training cost: 0.07036612752598624 validation cost0.06882171224581486: \n",
      "training mae: 0.28919239400929647 validation mae0.2879797703380453: \n",
      "Epochs: 57/500: \n",
      "training cost: 0.06987574137918999 validation cost0.06834228185288707: \n",
      "training mae: 0.2881460440903247 validation mae0.28693083501597555: \n",
      "Epochs: 58/500: \n",
      "training cost: 0.06939380873525444 validation cost0.06787122414109518: \n",
      "training mae: 0.28711162783828703 validation mae0.2858952008282244: \n",
      "Epochs: 59/500: \n",
      "training cost: 0.0689201733780071 validation cost0.06740838294961302: \n",
      "training mae: 0.2860891853365169 validation mae0.28487181826314323: \n",
      "Epochs: 60/500: \n",
      "training cost: 0.06845468216029586 validation cost0.06695360522793552: \n",
      "training mae: 0.285080478730016 validation mae0.28386117734916977: \n",
      "Epochs: 61/500: \n",
      "training cost: 0.06799718494007545 validation cost0.06650674096805345: \n",
      "training mae: 0.28408449765611415 validation mae0.28286193986114333: \n",
      "Epochs: 62/500: \n",
      "training cost: 0.0675475345179395 validation cost0.06606764313845376: \n",
      "training mae: 0.283099702465934 validation mae0.28187362660250326: \n",
      "Epochs: 63/500: \n",
      "training cost: 0.06710558657605437 validation cost0.06563616761986424: \n",
      "training mae: 0.282125539855546 validation mae0.28089718359730176: \n",
      "Epochs: 64/500: \n",
      "training cost: 0.06667119961845384 validation cost0.06521217314266632: \n",
      "training mae: 0.2811624337771284 validation mae0.2799336708698177: \n",
      "Epochs: 65/500: \n",
      "training cost: 0.06624423491265635 validation cost0.06479552122590772: \n",
      "training mae: 0.280210201605432 validation mae0.27898386639814465: \n",
      "Epochs: 66/500: \n",
      "training cost: 0.06582455643256924 validation cost0.06438607611785044: \n",
      "training mae: 0.2792718830523505 validation mae0.27804675099433607: \n",
      "Epochs: 67/500: \n",
      "training cost: 0.06541203080264578 validation cost0.06398370473799607: \n",
      "training mae: 0.2783449893238666 validation mae0.27712091672436057: \n",
      "Epochs: 68/500: \n",
      "training cost: 0.0650065272432637 validation cost0.0635882766205332: \n",
      "training mae: 0.2774296975229202 validation mae0.2762066976882748: \n",
      "Epochs: 69/500: \n",
      "training cost: 0.06460791751729357 validation cost0.06319966385915643: \n",
      "training mae: 0.2765252519676976 validation mae0.2753035386208707: \n",
      "Epochs: 70/500: \n",
      "training cost: 0.06421607587782889 validation cost0.06281774105320964: \n",
      "training mae: 0.27563189446431496 validation mae0.274411583742655: \n",
      "Epochs: 71/500: \n",
      "training cost: 0.06383087901704904 validation cost0.06244238525510892: \n",
      "training mae: 0.2747496823360317 validation mae0.273531902950688: \n",
      "Epochs: 72/500: \n",
      "training cost: 0.06345220601618858 validation cost0.06207347591900369: \n",
      "training mae: 0.2738774549092028 validation mae0.2726651820387652: \n",
      "Epochs: 73/500: \n",
      "training cost: 0.06307993829658662 validation cost0.061710894850636605: \n",
      "training mae: 0.2730161769844385 validation mae0.27180831782400044: \n",
      "Epochs: 74/500: \n",
      "training cost: 0.06271395957179116 validation cost0.061354526158365646: \n",
      "training mae: 0.27216582726785743 validation mae0.2709629570157722: \n",
      "Epochs: 75/500: \n",
      "training cost: 0.062354155800693915 validation cost0.061004256205312794: \n",
      "training mae: 0.27132558911152466 validation mae0.27012986318900706: \n",
      "Epochs: 76/500: \n",
      "training cost: 0.06200041514167219 validation cost0.060659973562606696: \n",
      "training mae: 0.27049680372197865 validation mae0.2693075971777802: \n",
      "Epochs: 77/500: \n",
      "training cost: 0.06165262790771454 validation cost0.06032156896368748: \n",
      "training mae: 0.2696797378519192 validation mae0.2684951655154364: \n",
      "Epochs: 78/500: \n",
      "training cost: 0.06131068652250815 validation cost0.05998893525964388: \n",
      "training mae: 0.26887395453339064 validation mae0.2676931627601433: \n",
      "Epochs: 79/500: \n",
      "training cost: 0.06097448547746606 validation cost0.05966196737555377: \n",
      "training mae: 0.2680787745566203 validation mae0.2669017906829517: \n",
      "Epochs: 80/500: \n",
      "training cost: 0.06064392128967302 validation cost0.059340562267801274: \n",
      "training mae: 0.26729505670584147 validation mae0.26611923329900855: \n",
      "Epochs: 81/500: \n",
      "training cost: 0.0603188924607296 validation cost0.0590246188823438: \n",
      "training mae: 0.2665223543437604 validation mae0.26534623227514237: \n",
      "Epochs: 82/500: \n",
      "training cost: 0.05999929943647418 validation cost0.058714038113904236: \n",
      "training mae: 0.26575911366357974 validation mae0.26458430333987676: \n",
      "Epochs: 83/500: \n",
      "training cost: 0.05968504456756346 validation cost0.05840872276606406: \n",
      "training mae: 0.2650062813583241 validation mae0.26383391300104303: \n",
      "Epochs: 84/500: \n",
      "training cost: 0.05937603207089211 validation cost0.058108577512234375: \n",
      "training mae: 0.26426227697335686 validation mae0.2630945842453002: \n",
      "Epochs: 85/500: \n",
      "training cost: 0.059072167991833215 validation cost0.057813508857482446: \n",
      "training mae: 0.26352658652475797 validation mae0.2623683095770257: \n",
      "Epochs: 86/500: \n",
      "training cost: 0.058773360167281026 validation cost0.057523425101192495: \n",
      "training mae: 0.262799816105342 validation mae0.26165102935113244: \n",
      "Epochs: 87/500: \n",
      "training cost: 0.05847951818947842 validation cost0.05723823630053981: \n",
      "training mae: 0.26208183561819226 validation mae0.260943327320029: \n",
      "Epochs: 88/500: \n",
      "training cost: 0.05819055337061156 validation cost0.05695785423475839: \n",
      "training mae: 0.26137273632040814 validation mae0.26024519900760645: \n",
      "Epochs: 89/500: \n",
      "training cost: 0.05790637870815491 validation cost0.05668219237018272: \n",
      "training mae: 0.260673743185399 validation mae0.2595566568990426: \n",
      "Epochs: 90/500: \n",
      "training cost: 0.057626908850950016 validation cost0.056411165826044996: \n",
      "training mae: 0.2599845274342632 validation mae0.258876588828643: \n",
      "Epochs: 91/500: \n",
      "training cost: 0.05735206006600185 validation cost0.05614469134100983: \n",
      "training mae: 0.2593036472444977 validation mae0.2582037584582128: \n",
      "Epochs: 92/500: \n",
      "training cost: 0.05708175020597681 validation cost0.055882687240428566: \n",
      "training mae: 0.25863109928315403 validation mae0.2575399781759338: \n",
      "Epochs: 93/500: \n",
      "training cost: 0.05681589867738719 validation cost0.05562507340429677: \n",
      "training mae: 0.25796630507308344 validation mae0.2568861025640232: \n",
      "Epochs: 94/500: \n",
      "training cost: 0.05655442640944673 validation cost0.0553717712358978: \n",
      "training mae: 0.2573107893776271 validation mae0.25624076501723025: \n",
      "Epochs: 95/500: \n",
      "training cost: 0.056297255823582755 validation cost0.055122703631117: \n",
      "training mae: 0.25666333869255137 validation mae0.25560370342255617: \n",
      "Epochs: 96/500: \n",
      "training cost: 0.0560443108035902 validation cost0.054877794948410524: \n",
      "training mae: 0.2560246484425857 validation mae0.25497481537232053: \n",
      "Epochs: 97/500: \n",
      "training cost: 0.05579551666641384 validation cost0.05463697097941399: \n",
      "training mae: 0.25539565153541616 validation mae0.25435326317253787: \n",
      "Epochs: 98/500: \n",
      "training cost: 0.055550800133544506 validation cost0.054400158920176085: \n",
      "training mae: 0.25477497842012875 validation mae0.2537384819961997: \n",
      "Epochs: 99/500: \n",
      "training cost: 0.05531008930301615 validation cost0.054167287343003: \n",
      "training mae: 0.2541627151401642 validation mae0.25313173751289214: \n",
      "Epochs: 100/500: \n",
      "training cost: 0.055073313621990576 validation cost0.053938286168899605: \n",
      "training mae: 0.25355760529495175 validation mae0.2525342191712101: \n",
      "Epochs: 101/500: \n",
      "training cost: 0.05484040385991679 validation cost0.05371308664059402: \n",
      "training mae: 0.25296029113354035 validation mae0.2519463932516612: \n",
      "Epochs: 102/500: \n",
      "training cost: 0.054611292082252696 validation cost0.0534916212961322: \n",
      "training mae: 0.2523701342886094 validation mae0.2513674781531368: \n",
      "Epochs: 103/500: \n",
      "training cost: 0.05438591162473656 validation cost0.053273823943029874: \n",
      "training mae: 0.2517875535151711 validation mae0.25079526384193906: \n",
      "Epochs: 104/500: \n",
      "training cost: 0.054164197068196585 validation cost0.05305962963296922: \n",
      "training mae: 0.25121298285650645 validation mae0.25023005266273535: \n",
      "Epochs: 105/500: \n",
      "training cost: 0.05394608421388643 validation cost0.05284897463702812: \n",
      "training mae: 0.2506460364930272 validation mae0.24967290855412663: \n",
      "Epochs: 106/500: \n",
      "training cost: 0.053731510059335685 validation cost0.052641796421430076: \n",
      "training mae: 0.25008582353879927 validation mae0.24912276560955168: \n",
      "Epochs: 107/500: \n",
      "training cost: 0.05352041277470382 validation cost0.052438033623803296: \n",
      "training mae: 0.24953266111571115 validation mae0.248581797821707: \n",
      "Epochs: 108/500: \n",
      "training cost: 0.053312731679626545 validation cost0.0522376260299374: \n",
      "training mae: 0.24898664546076488 validation mae0.24804690114119302: \n",
      "Epochs: 109/500: \n",
      "training cost: 0.053108407220544204 validation cost0.052040514551027095: \n",
      "training mae: 0.24844695727776267 validation mae0.2475217397373514: \n",
      "Epochs: 110/500: \n",
      "training cost: 0.052907380948501545 validation cost0.05184664120139158: \n",
      "training mae: 0.247914883109182 validation mae0.2470044603241327: \n",
      "Epochs: 111/500: \n",
      "training cost: 0.05270959549740853 validation cost0.051655949076659755: \n",
      "training mae: 0.2473894660831165 validation mae0.24649313809725878: \n",
      "Epochs: 112/500: \n",
      "training cost: 0.052514994562752396 validation cost0.0514683823324103: \n",
      "training mae: 0.24687121856319047 validation mae0.2459878778638253: \n",
      "Epochs: 113/500: \n",
      "training cost: 0.0523235228807511 validation cost0.05128388616325728: \n",
      "training mae: 0.24635922008654149 validation mae0.24548894398480814: \n",
      "Epochs: 114/500: \n",
      "training cost: 0.05213512620793855 validation cost0.051102406782371074: \n",
      "training mae: 0.2458525517885905 validation mae0.2449957545243665: \n",
      "Epochs: 115/500: \n",
      "training cost: 0.051949751301172284 validation cost0.050923891401425114: \n",
      "training mae: 0.2453523760038309 validation mae0.2445096101979365: \n",
      "Epochs: 116/500: \n",
      "training cost: 0.051767345898054484 validation cost0.05074828821095953: \n",
      "training mae: 0.24485812133873022 validation mae0.24403055485378053: \n",
      "Epochs: 117/500: \n",
      "training cost: 0.05158785869775752 validation cost0.05057554636115197: \n",
      "training mae: 0.24437078999447573 validation mae0.24355779459634622: \n",
      "Epochs: 118/500: \n",
      "training cost: 0.05141123934224494 validation cost0.05040561594298718: \n",
      "training mae: 0.24388988514005613 validation mae0.24309306949842494: \n",
      "Epochs: 119/500: \n",
      "training cost: 0.05123743839787979 validation cost0.05023844796981653: \n",
      "training mae: 0.24341470304911167 validation mae0.24263619288029759: \n",
      "Epochs: 120/500: \n",
      "training cost: 0.05106640733741163 validation cost0.05007399435929898: \n",
      "training mae: 0.24294557599262878 validation mae0.24218613136128522: \n",
      "Epochs: 121/500: \n",
      "training cost: 0.050898098522334165 validation cost0.049912207915715136: \n",
      "training mae: 0.24248232056453295 validation mae0.24174091527784178: \n",
      "Epochs: 122/500: \n",
      "training cost: 0.05073246518560557 validation cost0.04975304231264651: \n",
      "training mae: 0.24202481824631472 validation mae0.2413013547878602: \n",
      "Epochs: 123/500: \n",
      "training cost: 0.0505694614147236 validation cost0.049596452076011835: \n",
      "training mae: 0.2415729532042814 validation mae0.24086819530923337: \n",
      "Epochs: 124/500: \n",
      "training cost: 0.050409042135147984 validation cost0.04944239256745288: \n",
      "training mae: 0.2411280202731317 validation mae0.24043999979144542: \n",
      "Epochs: 125/500: \n",
      "training cost: 0.050251163094062565 validation cost0.04929081996806204: \n",
      "training mae: 0.24068854889065233 validation mae0.2400174709635015: \n",
      "Epochs: 126/500: \n",
      "training cost: 0.05009578084446982 validation cost0.049141691262444706: \n",
      "training mae: 0.24025473069851497 validation mae0.2395994241606939: \n",
      "Epochs: 127/500: \n",
      "training cost: 0.04994285272961087 validation cost0.04899496422310844: \n",
      "training mae: 0.23982708688441567 validation mae0.239185929965792: \n",
      "Epochs: 128/500: \n",
      "training cost: 0.04979233686770375 validation cost0.04885059739517294: \n",
      "training mae: 0.23940383399718784 validation mae0.23877648267918009: \n",
      "Epochs: 129/500: \n",
      "training cost: 0.04964419213699326 validation cost0.048708550081392875: \n",
      "training mae: 0.23898514108566302 validation mae0.23837194757655294: \n",
      "Epochs: 130/500: \n",
      "training cost: 0.04949837816110569 validation cost0.04856878232748768: \n",
      "training mae: 0.23857116774193815 validation mae0.23797265988998878: \n",
      "Epochs: 131/500: \n",
      "training cost: 0.049354855294701995 validation cost0.04843125490777113: \n",
      "training mae: 0.23816343332558151 validation mae0.23757834923853866: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 132/500: \n",
      "training cost: 0.04921358460942289 validation cost0.048295929311074626: \n",
      "training mae: 0.2377616769437456 validation mae0.2371896407800018: \n",
      "Epochs: 133/500: \n",
      "training cost: 0.0490745278801197 validation cost0.04816276772695778: \n",
      "training mae: 0.23736546656882637 validation mae0.23680614573954625: \n",
      "Epochs: 134/500: \n",
      "training cost: 0.048937647571364915 validation cost0.04803173303220005: \n",
      "training mae: 0.23697513308290058 validation mae0.23642814354891464: \n",
      "Epochs: 135/500: \n",
      "training cost: 0.04880290682423655 validation cost0.04790278877756761: \n",
      "training mae: 0.23659007972989538 validation mae0.23605457247760736: \n",
      "Epochs: 136/500: \n",
      "training cost: 0.0486702694433702 validation cost0.0477758991748494: \n",
      "training mae: 0.23621013349354353 validation mae0.23568589849286778: \n",
      "Epochs: 137/500: \n",
      "training cost: 0.04853969988427346 validation cost0.0476510290841567: \n",
      "training mae: 0.23583570254301175 validation mae0.23532145460886167: \n",
      "Epochs: 138/500: \n",
      "training cost: 0.04841116324089693 validation cost0.04752814400148055: \n",
      "training mae: 0.23546511987995902 validation mae0.23496084921719745: \n",
      "Epochs: 139/500: \n",
      "training cost: 0.04828462523345625 validation cost0.04740721004650165: \n",
      "training mae: 0.23509936725656919 validation mae0.23460434068788266: \n",
      "Epochs: 140/500: \n",
      "training cost: 0.048160052196500214 validation cost0.04728819395064716: \n",
      "training mae: 0.23473853613318868 validation mae0.23425312855125513: \n",
      "Epochs: 141/500: \n",
      "training cost: 0.04803741106721932 validation cost0.04717106304538927: \n",
      "training mae: 0.2343820528482232 validation mae0.2339058058626278: \n",
      "Epochs: 142/500: \n",
      "training cost: 0.04791666937398995 validation cost0.04705578525078046: \n",
      "training mae: 0.2340302497277219 validation mae0.2335627792857591: \n",
      "Epochs: 143/500: \n",
      "training cost: 0.04779779522514904 validation cost0.04694232906422032: \n",
      "training mae: 0.2336825555166773 validation mae0.23322327169364027: \n",
      "Epochs: 144/500: \n",
      "training cost: 0.047680757297994494 validation cost0.04683066354944898: \n",
      "training mae: 0.23334005983838052 validation mae0.2328904431587162: \n",
      "Epochs: 145/500: \n",
      "training cost: 0.04756552482800643 validation cost0.04672075832576255: \n",
      "training mae: 0.23300224586638424 validation mae0.2325621332160677: \n",
      "Epochs: 146/500: \n",
      "training cost: 0.04745206759828476 validation cost0.0466125835574456: \n",
      "training mae: 0.23266854366853298 validation mae0.23223792045470262: \n",
      "Epochs: 147/500: \n",
      "training cost: 0.04734035592919838 validation cost0.04650610994341633: \n",
      "training mae: 0.23233992637217124 validation mae0.23191849999927544: \n",
      "Epochs: 148/500: \n",
      "training cost: 0.047230360668241524 validation cost0.046401308707079765: \n",
      "training mae: 0.23201550410405486 validation mae0.23160337985913745: \n",
      "Epochs: 149/500: \n",
      "training cost: 0.04712205318009323 validation cost0.04629815158638471: \n",
      "training mae: 0.23169555815277168 validation mae0.2312921384766421: \n",
      "Epochs: 150/500: \n",
      "training cost: 0.04701540533687506 validation cost0.04619661082408: \n",
      "training mae: 0.2313807302403987 validation mae0.23098548545513106: \n",
      "Epochs: 151/500: \n",
      "training cost: 0.04691038950860351 validation cost0.046096659158166076: \n",
      "training mae: 0.2310709348100484 validation mae0.23068390272226413: \n",
      "Epochs: 152/500: \n",
      "training cost: 0.04680697855383264 validation cost0.045998269812537525: \n",
      "training mae: 0.23076559319485082 validation mae0.23038780836791156: \n",
      "Epochs: 153/500: \n",
      "training cost: 0.046705145810483024 validation cost0.045901416487812784: \n",
      "training mae: 0.23046457359194158 validation mae0.2300952214234391: \n",
      "Epochs: 154/500: \n",
      "training cost: 0.046604865086853235 validation cost0.04580607335234687: \n",
      "training mae: 0.23016788571761151 validation mae0.22980698593130527: \n",
      "Epochs: 155/500: \n",
      "training cost: 0.04650611065280991 validation cost0.04571221503342355: \n",
      "training mae: 0.22987575511672695 validation mae0.2295230763156507: \n",
      "Epochs: 156/500: \n",
      "training cost: 0.04640885723115259 validation cost0.04561981660862281: \n",
      "training mae: 0.2295886719877073 validation mae0.2292429522426945: \n",
      "Epochs: 157/500: \n",
      "training cost: 0.046313079989149984 validation cost0.045528853597360426: \n",
      "training mae: 0.2293050399695481 validation mae0.2289664466975065: \n",
      "Epochs: 158/500: \n",
      "training cost: 0.04621875453024371 validation cost0.04543930195259554: \n",
      "training mae: 0.22902497662699997 validation mae0.22869518735213368: \n",
      "Epochs: 159/500: \n",
      "training cost: 0.04612585688591635 validation cost0.04535113805270312: \n",
      "training mae: 0.2287491771849726 validation mae0.22842846977291006: \n",
      "Epochs: 160/500: \n",
      "training cost: 0.046034363507720014 validation cost0.045264338693507676: \n",
      "training mae: 0.22847827983990165 validation mae0.22816549864103128: \n",
      "Epochs: 161/500: \n",
      "training cost: 0.04594425125946254 validation cost0.04517888108047478: \n",
      "training mae: 0.2282122181903051 validation mae0.22790540549018984: \n",
      "Epochs: 162/500: \n",
      "training cost: 0.04585549740954763 validation cost0.04509474282105734: \n",
      "training mae: 0.22795043341688923 validation mae0.22764962294626545: \n",
      "Epochs: 163/500: \n",
      "training cost: 0.04576807962346592 validation cost0.04501190191719319: \n",
      "training mae: 0.22769170689057605 validation mae0.22739856261230132: \n",
      "Epochs: 164/500: \n",
      "training cost: 0.04568197595643392 validation cost0.04493033675795089: \n",
      "training mae: 0.22743662836846046 validation mae0.2271512830748313: \n",
      "Epochs: 165/500: \n",
      "training cost: 0.04559716484617751 validation cost0.044850026112320814: \n",
      "training mae: 0.2271850220158152 validation mae0.2269092018527591: \n",
      "Epochs: 166/500: \n",
      "training cost: 0.045513625105857304 validation cost0.044770949122148164: \n",
      "training mae: 0.22693648938812636 validation mae0.22667079640923568: \n",
      "Epochs: 167/500: \n",
      "training cost: 0.04543133591713255 validation cost0.044693085295205374: \n",
      "training mae: 0.22669067007589358 validation mae0.22643697159336845: \n",
      "Epochs: 168/500: \n",
      "training cost: 0.04535027682336129 validation cost0.04461641449840067: \n",
      "training mae: 0.22644833466309242 validation mae0.2262066087020383: \n",
      "Epochs: 169/500: \n",
      "training cost: 0.045270427722933194 validation cost0.04454091695112015: \n",
      "training mae: 0.22620939343952956 validation mae0.22597985962145803: \n",
      "Epochs: 170/500: \n",
      "training cost: 0.0451917688627331 validation cost0.04446657321870057: \n",
      "training mae: 0.22597319226763152 validation mae0.22575671779590417: \n",
      "Epochs: 171/500: \n",
      "training cost: 0.045114280831731954 validation cost0.04439336420603012: \n",
      "training mae: 0.2257399895080019 validation mae0.22553725004442926: \n",
      "Epochs: 172/500: \n",
      "training cost: 0.04503794455470289 validation cost0.04432127115127457: \n",
      "training mae: 0.22551006386163358 validation mae0.22532200512256492: \n",
      "Epochs: 173/500: \n",
      "training cost: 0.04496274128605978 validation cost0.044250275619726116: \n",
      "training mae: 0.225283596670688 validation mae0.22510920738429901: \n",
      "Epochs: 174/500: \n",
      "training cost: 0.0448886526038156 validation cost0.044180359497772555: \n",
      "training mae: 0.22506080750846982 validation mae0.2248994084842226: \n",
      "Epochs: 175/500: \n",
      "training cost: 0.044815660403658406 validation cost0.04411150498698413: \n",
      "training mae: 0.22484112952422688 validation mae0.22469211998560407: \n",
      "Epochs: 176/500: \n",
      "training cost: 0.04474374689314221 validation cost0.04404369459831575: \n",
      "training mae: 0.2246242162202181 validation mae0.22448715901103125: \n",
      "Epochs: 177/500: \n",
      "training cost: 0.04467289458599068 validation cost0.04397691114642213: \n",
      "training mae: 0.22441026737576258 validation mae0.2242846403742961: \n",
      "Epochs: 178/500: \n",
      "training cost: 0.04460308629651113 validation cost0.043911137744083596: \n",
      "training mae: 0.2241990711800387 validation mae0.22408542267468107: \n",
      "Epochs: 179/500: \n",
      "training cost: 0.04453430513411673 validation cost0.04384635779674021: \n",
      "training mae: 0.22399060657529188 validation mae0.22388906824055993: \n",
      "Epochs: 180/500: \n",
      "training cost: 0.044466534497954485 validation cost0.04378255499713209: \n",
      "training mae: 0.22378485363492656 validation mae0.22369539898173652: \n",
      "Epochs: 181/500: \n",
      "training cost: 0.04439975807163715 validation cost0.04371971332004362: \n",
      "training mae: 0.22358170038248648 validation mae0.22350593359745777: \n",
      "Epochs: 182/500: \n",
      "training cost: 0.04433395981807659 validation cost0.043657817017149526: \n",
      "training mae: 0.22338148022467927 validation mae0.22332003746776535: \n",
      "Epochs: 183/500: \n",
      "training cost: 0.04426912397441682 validation cost0.043596850611960766: \n",
      "training mae: 0.2231843352821026 validation mae0.22313765242887218: \n",
      "Epochs: 184/500: \n",
      "training cost: 0.044205235047064535 validation cost0.043536798894868: \n",
      "training mae: 0.22298964983138933 validation mae0.2229579544941062: \n",
      "Epochs: 185/500: \n",
      "training cost: 0.04414227780681521 validation cost0.043477646918280884: \n",
      "training mae: 0.2227973660595158 validation mae0.22278080092197933: \n",
      "Epochs: 186/500: \n",
      "training cost: 0.044080237284072774 validation cost0.04341937999186107: \n",
      "training mae: 0.22260799613742238 validation mae0.2226060907853018: \n",
      "Epochs: 187/500: \n",
      "training cost: 0.044019098764160956 validation cost0.04336198367784712: \n",
      "training mae: 0.2224216912811048 validation mae0.22243339420555786: \n",
      "Epochs: 188/500: \n",
      "training cost: 0.04395884778272461 validation cost0.04330544378646931: \n",
      "training mae: 0.22223796154125502 validation mae0.2222629826542825: \n",
      "Epochs: 189/500: \n",
      "training cost: 0.04389947012121884 validation cost0.04324974637145269: \n",
      "training mae: 0.22205702788206286 validation mae0.22209440439526348: \n",
      "Epochs: 190/500: \n",
      "training cost: 0.043840951802484644 validation cost0.043194877725606436: \n",
      "training mae: 0.22187892418503438 validation mae0.22192732151042616: \n",
      "Epochs: 191/500: \n",
      "training cost: 0.04378327908640877 validation cost0.04314082437649788: \n",
      "training mae: 0.22170361175986925 validation mae0.22176290430508871: \n",
      "Epochs: 192/500: \n",
      "training cost: 0.04372643846566657 validation cost0.04308757308220933: \n",
      "training mae: 0.22153094796437678 validation mae0.22160128116992112: \n",
      "Epochs: 193/500: \n",
      "training cost: 0.043670416661545856 validation cost0.04303511082717622: \n",
      "training mae: 0.2213607080471337 validation mae0.22144251693653613: \n",
      "Epochs: 194/500: \n",
      "training cost: 0.043615200619850296 validation cost0.042983424818104785: \n",
      "training mae: 0.22119268360355013 validation mae0.22128642297538642: \n",
      "Epochs: 195/500: \n",
      "training cost: 0.04356077750688066 validation cost0.04293250247996769: \n",
      "training mae: 0.22102671620635447 validation mae0.22113254299462343: \n",
      "Epochs: 196/500: \n",
      "training cost: 0.04350713470549238 validation cost0.04288233145207606: \n",
      "training mae: 0.22086279599277636 validation mae0.2209810997527096: \n",
      "Epochs: 197/500: \n",
      "training cost: 0.04345425981122794 validation cost0.04283289958422639: \n",
      "training mae: 0.22070129299537777 validation mae0.22083198500547438: \n",
      "Epochs: 198/500: \n",
      "training cost: 0.043402140628522455 validation cost0.042784194932920724: \n",
      "training mae: 0.2205420834108932 validation mae0.22068464006886232: \n",
      "Epochs: 199/500: \n",
      "training cost: 0.0433507651669811 validation cost0.042736205757658824: \n",
      "training mae: 0.2203846659689179 validation mae0.22053931835429202: \n",
      "Epochs: 200/500: \n",
      "training cost: 0.04330012163772697 validation cost0.0426889205173006: \n",
      "training mae: 0.22022962433932158 validation mae0.22039606374547846: \n",
      "Epochs: 201/500: \n",
      "training cost: 0.04325019844981782 validation cost0.04264232786649769: \n",
      "training mae: 0.22007645026749023 validation mae0.22025515984504687: \n",
      "Epochs: 202/500: \n",
      "training cost: 0.04320098420673039 validation cost0.04259641665219257: \n",
      "training mae: 0.219925854943122 validation mae0.22011626531068498: \n",
      "Epochs: 203/500: \n",
      "training cost: 0.04315246770291096 validation cost0.04255117591018401: \n",
      "training mae: 0.219777688030381 validation mae0.2199791161291901: \n",
      "Epochs: 204/500: \n",
      "training cost: 0.04310463792039094 validation cost0.04250659486175734: \n",
      "training mae: 0.2196316817791565 validation mae0.2198446545961526: \n",
      "Epochs: 205/500: \n",
      "training cost: 0.04305748402546589 validation cost0.04246266291037854: \n",
      "training mae: 0.21948732459530323 validation mae0.21971214993966012: \n",
      "Epochs: 206/500: \n",
      "training cost: 0.04301099536543698 validation cost0.04241936963845051: \n",
      "training mae: 0.21934502431205935 validation mae0.21958138215162984: \n",
      "Epochs: 207/500: \n",
      "training cost: 0.042965161465413584 validation cost0.04237670480413062: \n",
      "training mae: 0.21920484847439173 validation mae0.21945230349866773: \n",
      "Epochs: 208/500: \n",
      "training cost: 0.04291997202517572 validation cost0.04233465833820804: \n",
      "training mae: 0.2190666812009452 validation mae0.21932423356324815: \n",
      "Epochs: 209/500: \n",
      "training cost: 0.04287541691609523 validation cost0.042293220341039876: \n",
      "training mae: 0.2189301496995001 validation mae0.21919745729246543: \n",
      "Epochs: 210/500: \n",
      "training cost: 0.04283148617811448 validation cost0.04225238107954482: \n",
      "training mae: 0.21879536024089047 validation mae0.21907222145057223: \n",
      "Epochs: 211/500: \n",
      "training cost: 0.04278817001678147 validation cost0.042212130984253124: \n",
      "training mae: 0.21866277579733367 validation mae0.21894929021305232: \n",
      "Epochs: 212/500: \n",
      "training cost: 0.04274545880034024 validation cost0.04217246064641201: \n",
      "training mae: 0.2185320654020731 validation mae0.21882781036831822: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 213/500: \n",
      "training cost: 0.04270334305687547 validation cost0.04213336081514511: \n",
      "training mae: 0.2184033578830626 validation mae0.21870822600021017: \n",
      "Epochs: 214/500: \n",
      "training cost: 0.04266181347151016 validation cost0.04209482239466511: \n",
      "training mae: 0.2182766861018356 validation mae0.21859058442545085: \n",
      "Epochs: 215/500: \n",
      "training cost: 0.04262086088365549 validation cost0.0420568364415384: \n",
      "training mae: 0.21815171152652874 validation mae0.21847493783045716: \n",
      "Epochs: 216/500: \n",
      "training cost: 0.042580476284311636 validation cost0.04201939416200082: \n",
      "training mae: 0.21802865625198956 validation mae0.21836100520041024: \n",
      "Epochs: 217/500: \n",
      "training cost: 0.042540650813418616 validation cost0.04198248690932329: \n",
      "training mae: 0.21790791428648168 validation mae0.21824865372029612: \n",
      "Epochs: 218/500: \n",
      "training cost: 0.04250137575725633 validation cost0.041946106181226676: \n",
      "training mae: 0.21778900676527257 validation mae0.21813816704695702: \n",
      "Epochs: 219/500: \n",
      "training cost: 0.04246264254589256 validation cost0.041910243617344536: \n",
      "training mae: 0.21767150068241495 validation mae0.2180287708235811: \n",
      "Epochs: 220/500: \n",
      "training cost: 0.04242444275067822 validation cost0.041874890996733104: \n",
      "training mae: 0.2175559354962686 validation mae0.21792054669173727: \n",
      "Epochs: 221/500: \n",
      "training cost: 0.042386768081788755 validation cost0.04184004023542738: \n",
      "training mae: 0.21744217573311428 validation mae0.2178137579092197: \n",
      "Epochs: 222/500: \n",
      "training cost: 0.042349610385810955 validation cost0.041805683384042655: \n",
      "training mae: 0.2173303131965789 validation mae0.21770840214112702: \n",
      "Epochs: 223/500: \n",
      "training cost: 0.042312961643374156 validation cost0.041771812625420214: \n",
      "training mae: 0.21722098775522536 validation mae0.21760435555767962: \n",
      "Epochs: 224/500: \n",
      "training cost: 0.04227681396682502 validation cost0.04173842027231677: \n",
      "training mae: 0.21711312204298494 validation mae0.2175016395300966: \n",
      "Epochs: 225/500: \n",
      "training cost: 0.04224115959794508 validation cost0.0417054987651365: \n",
      "training mae: 0.2170068391140884 validation mae0.2174005596180175: \n",
      "Epochs: 226/500: \n",
      "training cost: 0.04220599090571009 validation cost0.041673040669704856: \n",
      "training mae: 0.21690181118870436 validation mae0.21730091232705553: \n",
      "Epochs: 227/500: \n",
      "training cost: 0.04217130038409055 validation cost0.04164103867508351: \n",
      "training mae: 0.21679807198543308 validation mae0.2172029366685441: \n",
      "Epochs: 228/500: \n",
      "training cost: 0.042137080649892474 validation cost0.04160948559142546: \n",
      "training mae: 0.21669562140741108 validation mae0.2171068081607638: \n",
      "Epochs: 229/500: \n",
      "training cost: 0.04210332444063757 validation cost0.04157837434786956: \n",
      "training mae: 0.21659435593460982 validation mae0.21701192930349847: \n",
      "Epochs: 230/500: \n",
      "training cost: 0.04207002461248233 validation cost0.0415476979904738: \n",
      "training mae: 0.21649464554273312 validation mae0.21691802172042546: \n",
      "Epochs: 231/500: \n",
      "training cost: 0.042037174138174885 validation cost0.04151744968018642: \n",
      "training mae: 0.21639655577277633 validation mae0.21682538858253522: \n",
      "Epochs: 232/500: \n",
      "training cost: 0.04200476610504931 validation cost0.04148762269085421: \n",
      "training mae: 0.2162998912893057 validation mae0.2167340827524278: \n",
      "Epochs: 233/500: \n",
      "training cost: 0.04197279371305626 validation cost0.04145821040726738: \n",
      "training mae: 0.2162043082832755 validation mae0.21664408440220098: \n",
      "Epochs: 234/500: \n",
      "training cost: 0.04194125027282963 validation cost0.04142920632324001: \n",
      "training mae: 0.21611027292379764 validation mae0.216555585546264: \n",
      "Epochs: 235/500: \n",
      "training cost: 0.04191012920378811 validation cost0.04140060403972571: \n",
      "training mae: 0.2160178209930703 validation mae0.21646820669400468: \n",
      "Epochs: 236/500: \n",
      "training cost: 0.04187942403227138 validation cost0.04137239726296758: \n",
      "training mae: 0.21592697247734016 validation mae0.21638187662093789: \n",
      "Epochs: 237/500: \n",
      "training cost: 0.04184912838971006 validation cost0.04134457980268195: \n",
      "training mae: 0.21583800255085525 validation mae0.21629704054884769: \n",
      "Epochs: 238/500: \n",
      "training cost: 0.041819236010828674 validation cost0.04131714557027508: \n",
      "training mae: 0.21575031138373077 validation mae0.21621382342752338: \n",
      "Epochs: 239/500: \n",
      "training cost: 0.04178974073188127 validation cost0.04129008857709243: \n",
      "training mae: 0.2156637678414787 validation mae0.21613196179359162: \n",
      "Epochs: 240/500: \n",
      "training cost: 0.04176063648891883 validation cost0.04126340293269961: \n",
      "training mae: 0.21557831151544582 validation mae0.2160512753995037: \n",
      "Epochs: 241/500: \n",
      "training cost: 0.041731917316088 validation cost0.04123708284319462: \n",
      "training mae: 0.21549393534281297 validation mae0.21597148090908336: \n",
      "Epochs: 242/500: \n",
      "training cost: 0.041703577343960414 validation cost0.041211122609550614: \n",
      "training mae: 0.21541069325397394 validation mae0.21589231081733376: \n",
      "Epochs: 243/500: \n",
      "training cost: 0.04167561079789218 validation cost0.041185516625988704: \n",
      "training mae: 0.21532866133508538 validation mae0.21581450647313033: \n",
      "Epochs: 244/500: \n",
      "training cost: 0.041648011996412826 validation cost0.04116025937838019: \n",
      "training mae: 0.2152478421243721 validation mae0.21573784172965907: \n",
      "Epochs: 245/500: \n",
      "training cost: 0.04162077534964323 validation cost0.04113534544267766: \n",
      "training mae: 0.2151681490459684 validation mae0.215662026078843: \n",
      "Epochs: 246/500: \n",
      "training cost: 0.04159389535774191 validation cost0.04111076948337436: \n",
      "training mae: 0.2150894713956075 validation mae0.21558689866301622: \n",
      "Epochs: 247/500: \n",
      "training cost: 0.04156736660937917 validation cost0.041086526251991454: \n",
      "training mae: 0.21501186558350652 validation mae0.21551244224934005: \n",
      "Epochs: 248/500: \n",
      "training cost: 0.041541183780238564 validation cost0.041062610585592386: \n",
      "training mae: 0.21493527001972743 validation mae0.21543874071700175: \n",
      "Epochs: 249/500: \n",
      "training cost: 0.041515341631545265 validation cost0.041039017405324035: \n",
      "training mae: 0.21485986139970017 validation mae0.21536604748038873: \n",
      "Epochs: 250/500: \n",
      "training cost: 0.04148983500862051 validation cost0.04101574171498413: \n",
      "training mae: 0.21478571580836836 validation mae0.21529449765905365: \n",
      "Epochs: 251/500: \n",
      "training cost: 0.04146465883946213 validation cost0.04099277859961427: \n",
      "training mae: 0.21471294682169803 validation mae0.21522376171590013: \n",
      "Epochs: 252/500: \n",
      "training cost: 0.04143980813335013 validation cost0.04097012322411828: \n",
      "training mae: 0.2146411119199161 validation mae0.21515380750243895: \n",
      "Epochs: 253/500: \n",
      "training cost: 0.04141527797947724 validation cost0.04094777083190522: \n",
      "training mae: 0.2145703230774365 validation mae0.21508487174277513: \n",
      "Epochs: 254/500: \n",
      "training cost: 0.04139106354560383 validation cost0.040925716743556814: \n",
      "training mae: 0.21450068401837166 validation mae0.21501728489636127: \n",
      "Epochs: 255/500: \n",
      "training cost: 0.0413671600767367 validation cost0.040903956355518474: \n",
      "training mae: 0.2144319130933503 validation mae0.21495096528183752: \n",
      "Epochs: 256/500: \n",
      "training cost: 0.04134356289383129 validation cost0.04088248513881394: \n",
      "training mae: 0.2143644095013397 validation mae0.2148854084268472: \n",
      "Epochs: 257/500: \n",
      "training cost: 0.04132026739251695 validation cost0.04086129863778268: \n",
      "training mae: 0.2142980726799171 validation mae0.2148203901706728: \n",
      "Epochs: 258/500: \n",
      "training cost: 0.041297269041844775 validation cost0.04084039246883984: \n",
      "training mae: 0.2142327106782354 validation mae0.21475618282653686: \n",
      "Epochs: 259/500: \n",
      "training cost: 0.04127456338305763 validation cost0.04081976231925826: \n",
      "training mae: 0.21416832268383798 validation mae0.21469299595838878: \n",
      "Epochs: 260/500: \n",
      "training cost: 0.04125214602838182 validation cost0.04079940394597215: \n",
      "training mae: 0.21410495660036524 validation mae0.21463076474653936: \n",
      "Epochs: 261/500: \n",
      "training cost: 0.041230012659840214 validation cost0.04077931317440202: \n",
      "training mae: 0.21404264900025038 validation mae0.21456927743983673: \n",
      "Epochs: 262/500: \n",
      "training cost: 0.041208159028086194 validation cost0.04075948589730041: \n",
      "training mae: 0.21398119518771075 validation mae0.21450868386796007: \n",
      "Epochs: 263/500: \n",
      "training cost: 0.04118658095125824 validation cost0.04073991807361816: \n",
      "training mae: 0.2139206231476552 validation mae0.214449241697389: \n",
      "Epochs: 264/500: \n",
      "training cost: 0.041165274313854604 validation cost0.040720605727390655: \n",
      "training mae: 0.2138606954621022 validation mae0.21439091423608087: \n",
      "Epochs: 265/500: \n",
      "training cost: 0.04114423506562778 validation cost0.04070154494664383: \n",
      "training mae: 0.21380141516599904 validation mae0.21433377098408646: \n",
      "Epochs: 266/500: \n",
      "training cost: 0.041123459220498454 validation cost0.040682731882319544: \n",
      "training mae: 0.21374285673167237 validation mae0.21427739367689247: \n",
      "Epochs: 267/500: \n",
      "training cost: 0.04110294285548839 validation cost0.04066416274721976: \n",
      "training mae: 0.21368518087993263 validation mae0.2142216987580373: \n",
      "Epochs: 268/500: \n",
      "training cost: 0.04108268210967215 validation cost0.04064583381496955: \n",
      "training mae: 0.21362816800814607 validation mae0.21416691980161273: \n",
      "Epochs: 269/500: \n",
      "training cost: 0.041062673183147026 validation cost0.04062774141899818: \n",
      "training mae: 0.2135718217722592 validation mae0.21411269899400698: \n",
      "Epochs: 270/500: \n",
      "training cost: 0.0410429123360211 validation cost0.040609881951538244: \n",
      "training mae: 0.21351638149867844 validation mae0.21405917191557736: \n",
      "Epochs: 271/500: \n",
      "training cost: 0.04102339588741894 validation cost0.04059225186264234: \n",
      "training mae: 0.21346177633672125 validation mae0.2140068893248208: \n",
      "Epochs: 272/500: \n",
      "training cost: 0.04100412021450461 validation cost0.04057484765921701: \n",
      "training mae: 0.21340789782207542 validation mae0.21395539134753505: \n",
      "Epochs: 273/500: \n",
      "training cost: 0.040985081751521796 validation cost0.040557665904073635: \n",
      "training mae: 0.21335473262818724 validation mae0.21390449892182437: \n",
      "Epochs: 274/500: \n",
      "training cost: 0.04096627698885056 validation cost0.040540703214995935: \n",
      "training mae: 0.21330205264554936 validation mae0.21385406723191094: \n",
      "Epochs: 275/500: \n",
      "training cost: 0.04094770247208052 validation cost0.04052395626382388: \n",
      "training mae: 0.21325002931704082 validation mae0.21380417394147483: \n",
      "Epochs: 276/500: \n",
      "training cost: 0.04092935480110025 validation cost0.040507421775553464: \n",
      "training mae: 0.21319864049067383 validation mae0.2137549493600328: \n",
      "Epochs: 277/500: \n",
      "training cost: 0.04091123062920227 validation cost0.04049109652745238: \n",
      "training mae: 0.21314772971531115 validation mae0.21370636369089557: \n",
      "Epochs: 278/500: \n",
      "training cost: 0.04089332666220378 validation cost0.040474977348190985: \n",
      "training mae: 0.21309749100419062 validation mae0.2136584392154364: \n",
      "Epochs: 279/500: \n",
      "training cost: 0.04087563965758248 validation cost0.04045906111698849: \n",
      "training mae: 0.2130477456369435 validation mae0.21361130446024565: \n",
      "Epochs: 280/500: \n",
      "training cost: 0.040858166423627426 validation cost0.04044334476277404: \n",
      "training mae: 0.21299864848095018 validation mae0.213564626088619: \n",
      "Epochs: 281/500: \n",
      "training cost: 0.04084090381860448 validation cost0.04042782526336226: \n",
      "training mae: 0.21295033114378373 validation mae0.21351835872156388: \n",
      "Epochs: 282/500: \n",
      "training cost: 0.0408238487499363 validation cost0.04041249964464334: \n",
      "training mae: 0.21290260365200356 validation mae0.2134732160877756: \n",
      "Epochs: 283/500: \n",
      "training cost: 0.04080699817339638 validation cost0.040397364979787014: \n",
      "training mae: 0.21285550560909053 validation mae0.21342887560089022: \n",
      "Epochs: 284/500: \n",
      "training cost: 0.04079034909231696 validation cost0.04038241838846036: \n",
      "training mae: 0.2128090087840567 validation mae0.21338568443909425: \n",
      "Epochs: 285/500: \n",
      "training cost: 0.04077389855681071 validation cost0.040367657036059275: \n",
      "training mae: 0.21276316122577407 validation mae0.21334292659403742: \n",
      "Epochs: 286/500: \n",
      "training cost: 0.04075764366300565 validation cost0.04035307813295315: \n",
      "training mae: 0.21271786523402486 validation mae0.2133005555549389: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 287/500: \n",
      "training cost: 0.04074158155229328 validation cost0.0403386789337426: \n",
      "training mae: 0.21267295982717474 validation mae0.21325860623527695: \n",
      "Epochs: 288/500: \n",
      "training cost: 0.0407257094105897 validation cost0.040324456736530095: \n",
      "training mae: 0.21262860636244243 validation mae0.21321773478939385: \n",
      "Epochs: 289/500: \n",
      "training cost: 0.04071002446760922 validation cost0.040310408882203136: \n",
      "training mae: 0.21258477598755557 validation mae0.21317753754750837: \n",
      "Epochs: 290/500: \n",
      "training cost: 0.04069452399615054 validation cost0.04029653275372981: \n",
      "training mae: 0.2125414723952204 validation mae0.21313802016620859: \n",
      "Epochs: 291/500: \n",
      "training cost: 0.0406792053113952 validation cost0.040282825775466435: \n",
      "training mae: 0.2124988751148151 validation mae0.213099202932501: \n",
      "Epochs: 292/500: \n",
      "training cost: 0.04066406577021785 validation cost0.04026928541247719: \n",
      "training mae: 0.21245689759227127 validation mae0.21306105961154834: \n",
      "Epochs: 293/500: \n",
      "training cost: 0.04064910277050842 validation cost0.040255909169865406: \n",
      "training mae: 0.21241543557337222 validation mae0.21302349519766287: \n",
      "Epochs: 294/500: \n",
      "training cost: 0.040634313750505906 validation cost0.040242694592116324: \n",
      "training mae: 0.21237459310827542 validation mae0.21298619851376618: \n",
      "Epochs: 295/500: \n",
      "training cost: 0.04061969618814334 validation cost0.04022963926245121: \n",
      "training mae: 0.2123342595431092 validation mae0.2129492973760144: \n",
      "Epochs: 296/500: \n",
      "training cost: 0.04060524760040412 validation cost0.04021674080219243: \n",
      "training mae: 0.21229454635522593 validation mae0.21291287642320098: \n",
      "Epochs: 297/500: \n",
      "training cost: 0.040590965542689116 validation cost0.04020399687013954: \n",
      "training mae: 0.2122557753756792 validation mae0.2128769830645762: \n",
      "Epochs: 298/500: \n",
      "training cost: 0.04057684760819463 validation cost0.04019140516195591: \n",
      "training mae: 0.21221750125437921 validation mae0.21284157258025713: \n",
      "Epochs: 299/500: \n",
      "training cost: 0.04056289142730095 validation cost0.04017896340956593: \n",
      "training mae: 0.2121797539514195 validation mae0.21280652846243678: \n",
      "Epochs: 300/500: \n",
      "training cost: 0.040549094666971146 validation cost0.04016666938056248: \n",
      "training mae: 0.21214252961077468 validation mae0.21277174920893077: \n",
      "Epochs: 301/500: \n",
      "training cost: 0.040535455030160164 validation cost0.04015452087762456: \n",
      "training mae: 0.2121057555539623 validation mae0.2127374934844097: \n",
      "Epochs: 302/500: \n",
      "training cost: 0.040521970255233956 validation cost0.040142515737944744: \n",
      "training mae: 0.21206955754890824 validation mae0.21270371788647666: \n",
      "Epochs: 303/500: \n",
      "training cost: 0.04050863811539829 validation cost0.04013065183266649: \n",
      "training mae: 0.2120338144789581 validation mae0.21267022506458963: \n",
      "Epochs: 304/500: \n",
      "training cost: 0.040495456418137364 validation cost0.04011892706633095: \n",
      "training mae: 0.21199848251897788 validation mae0.21263712454206488: \n",
      "Epochs: 305/500: \n",
      "training cost: 0.04048242300466181 validation cost0.04010733937633327: \n",
      "training mae: 0.21196367849369066 validation mae0.2126045970961141: \n",
      "Epochs: 306/500: \n",
      "training cost: 0.04046953574936603 validation cost0.04009588673238807: \n",
      "training mae: 0.21192924421793297 validation mae0.21257272390266518: \n",
      "Epochs: 307/500: \n",
      "training cost: 0.040456792559294706 validation cost0.040084567136003925: \n",
      "training mae: 0.2118953009450036 validation mae0.21254123676364667: \n",
      "Epochs: 308/500: \n",
      "training cost: 0.04044419137361825 validation cost0.040073378619966966: \n",
      "training mae: 0.21186184750177936 validation mae0.21251012541593536: \n",
      "Epochs: 309/500: \n",
      "training cost: 0.04043173016311712 validation cost0.04006231924783298: \n",
      "training mae: 0.21182874252124775 validation mae0.21247924690435552: \n",
      "Epochs: 310/500: \n",
      "training cost: 0.04041940692967474 validation cost0.040051387113428295: \n",
      "training mae: 0.21179594076249436 validation mae0.21244869769564972: \n",
      "Epochs: 311/500: \n",
      "training cost: 0.04040721970577901 validation cost0.04004058034035901: \n",
      "training mae: 0.21176356284814768 validation mae0.21241834684712277: \n",
      "Epochs: 312/500: \n",
      "training cost: 0.04039516655403212 validation cost0.04002989708152855: \n",
      "training mae: 0.21173161166860438 validation mae0.2123884669541374: \n",
      "Epochs: 313/500: \n",
      "training cost: 0.040383245566668634 validation cost0.04001933551866332: \n",
      "training mae: 0.21170020684515248 validation mae0.21235896992995237: \n",
      "Epochs: 314/500: \n",
      "training cost: 0.04037145486508154 validation cost0.04000889386184645: \n",
      "training mae: 0.2116691292530387 validation mae0.21232994569028524: \n",
      "Epochs: 315/500: \n",
      "training cost: 0.040359792599356376 validation cost0.039998570349059334: \n",
      "training mae: 0.21163848144247488 validation mae0.21230146592625163: \n",
      "Epochs: 316/500: \n",
      "training cost: 0.04034825694781302 validation cost0.03998836324573085: \n",
      "training mae: 0.21160810843636998 validation mae0.21227315934953916: \n",
      "Epochs: 317/500: \n",
      "training cost: 0.04033684611655517 validation cost0.03997827084429422: \n",
      "training mae: 0.21157805044838915 validation mae0.21224500144321456: \n",
      "Epochs: 318/500: \n",
      "training cost: 0.040325558339027366 validation cost0.03996829146375138: \n",
      "training mae: 0.21154830544009293 validation mae0.21221722590697448: \n",
      "Epochs: 319/500: \n",
      "training cost: 0.04031439187557938 validation cost0.03995842344924447: \n",
      "training mae: 0.21151882694253352 validation mae0.21218980558011682: \n",
      "Epochs: 320/500: \n",
      "training cost: 0.04030334501303782 validation cost0.03994866517163472: \n",
      "training mae: 0.2114896379409498 validation mae0.2121627500410416: \n",
      "Epochs: 321/500: \n",
      "training cost: 0.04029241606428492 validation cost0.039939015027088305: \n",
      "training mae: 0.2114607048309093 validation mae0.2121359242692397: \n",
      "Epochs: 322/500: \n",
      "training cost: 0.04028160336784435 validation cost0.03992947143666906: \n",
      "training mae: 0.21143211399569603 validation mae0.21210923670242876: \n",
      "Epochs: 323/500: \n",
      "training cost: 0.04027090528747375 validation cost0.03992003284593821: \n",
      "training mae: 0.2114038841296505 validation mae0.21208282382206317: \n",
      "Epochs: 324/500: \n",
      "training cost: 0.040260320211764275 validation cost0.039910697724560566: \n",
      "training mae: 0.2113759593138302 validation mae0.21205673669611963: \n",
      "Epochs: 325/500: \n",
      "training cost: 0.040249846553746534 validation cost0.03990146456591748: \n",
      "training mae: 0.2113483633595225 validation mae0.2120308535985266: \n",
      "Epochs: 326/500: \n",
      "training cost: 0.04023948275050323 validation cost0.039892331886726126: \n",
      "training mae: 0.21132101776623097 validation mae0.21200530151067631: \n",
      "Epochs: 327/500: \n",
      "training cost: 0.04022922726278813 validation cost0.03988329822666525: \n",
      "training mae: 0.2112939441689547 validation mae0.2119800703127258: \n",
      "Epochs: 328/500: \n",
      "training cost: 0.040219078574651373 validation cost0.039874362148007055: \n",
      "training mae: 0.21126722819779137 validation mae0.21195538608295703: \n",
      "Epochs: 329/500: \n",
      "training cost: 0.040209035193070876 validation cost0.039865522235255295: \n",
      "training mae: 0.21124095047599456 validation mae0.21193101325473673: \n",
      "Epochs: 330/500: \n",
      "training cost: 0.04019909564759 validation cost0.03985677709478932: \n",
      "training mae: 0.21121500152248002 validation mae0.2119067994992554: \n",
      "Epochs: 331/500: \n",
      "training cost: 0.04018925848996102 validation cost0.03984812535451409: \n",
      "training mae: 0.21118942816902017 validation mae0.21188282028825148: \n",
      "Epochs: 332/500: \n",
      "training cost: 0.040179522293794574 validation cost0.039839565663515965: \n",
      "training mae: 0.2111642014030667 validation mae0.21185907307506913: \n",
      "Epochs: 333/500: \n",
      "training cost: 0.04016988565421483 validation cost0.03983109669172425: \n",
      "training mae: 0.211139214827934 validation mae0.2118355313917123: \n",
      "Epochs: 334/500: \n",
      "training cost: 0.04016034718752037 validation cost0.039822717129578335: \n",
      "training mae: 0.21111443666847593 validation mae0.21181213974240146: \n",
      "Epochs: 335/500: \n",
      "training cost: 0.0401509055308506 validation cost0.0398144256877003: \n",
      "training mae: 0.21109004555621078 validation mae0.2117890679538766: \n",
      "Epochs: 336/500: \n",
      "training cost: 0.04014155934185769 validation cost0.03980622109657302: \n",
      "training mae: 0.21106604264777515 validation mae0.21176632736023163: \n",
      "Epochs: 337/500: \n",
      "training cost: 0.040132307298383844 validation cost0.03979810210622355: \n",
      "training mae: 0.21104237515371413 validation mae0.2117439191486173: \n",
      "Epochs: 338/500: \n",
      "training cost: 0.04012314809814394 validation cost0.039790067485911775: \n",
      "training mae: 0.21101894090441486 validation mae0.2117216208026066: \n",
      "Epochs: 339/500: \n",
      "training cost: 0.04011408045841326 validation cost0.03978211602382411: \n",
      "training mae: 0.21099578187636522 validation mae0.21169946388090044: \n",
      "Epochs: 340/500: \n",
      "training cost: 0.04010510311572045 validation cost0.03977424652677243: \n",
      "training mae: 0.2109729451208356 validation mae0.2116776714979112: \n",
      "Epochs: 341/500: \n",
      "training cost: 0.04009621482554538 validation cost0.03976645781989776: \n",
      "training mae: 0.21095040794231298 validation mae0.21165630934249058: \n",
      "Epochs: 342/500: \n",
      "training cost: 0.040087414362022074 validation cost0.03975874874637901: \n",
      "training mae: 0.2109281481675141 validation mae0.2116352698189284: \n",
      "Epochs: 343/500: \n",
      "training cost: 0.04007870051764638 validation cost0.03975111816714643: \n",
      "training mae: 0.2109061000588461 validation mae0.21161450814144397: \n",
      "Epochs: 344/500: \n",
      "training cost: 0.04007007210298847 validation cost0.03974356496059979: \n",
      "training mae: 0.21088424905507114 validation mae0.21159408938909688: \n",
      "Epochs: 345/500: \n",
      "training cost: 0.04006152794641002 validation cost0.039736088022331174: \n",
      "training mae: 0.21086265318125255 validation mae0.21157394090547857: \n",
      "Epochs: 346/500: \n",
      "training cost: 0.04005306689378595 validation cost0.039728686264852424: \n",
      "training mae: 0.21084131896855987 validation mae0.21155410791042734: \n",
      "Epochs: 347/500: \n",
      "training cost: 0.0400446878082308 validation cost0.03972135861732686: \n",
      "training mae: 0.21082021839183032 validation mae0.21153440431907838: \n",
      "Epochs: 348/500: \n",
      "training cost: 0.04003638956982941 validation cost0.03971410402530567: \n",
      "training mae: 0.2107992885218549 validation mae0.21151488691337803: \n",
      "Epochs: 349/500: \n",
      "training cost: 0.04002817107537214 validation cost0.03970692145046836: \n",
      "training mae: 0.21077854947225644 validation mae0.21149555719803428: \n",
      "Epochs: 350/500: \n",
      "training cost: 0.04002003123809423 validation cost0.03969980987036764: \n",
      "training mae: 0.21075800173764295 validation mae0.21147642607901257: \n",
      "Epochs: 351/500: \n",
      "training cost: 0.04001196898741952 validation cost0.03969276827817837: \n",
      "training mae: 0.21073761456144352 validation mae0.21145754198229982: \n",
      "Epochs: 352/500: \n",
      "training cost: 0.04000398326870826 validation cost0.039685795682450724: \n",
      "training mae: 0.21071734710054904 validation mae0.211438797684865: \n",
      "Epochs: 353/500: \n",
      "training cost: 0.039996073043008964 validation cost0.03967889110686723: \n",
      "training mae: 0.2106972587471938 validation mae0.2114201747781654: \n",
      "Epochs: 354/500: \n",
      "training cost: 0.03998823728681445 validation cost0.03967205359000396: \n",
      "training mae: 0.21067750133417432 validation mae0.21140168534151002: \n",
      "Epochs: 355/500: \n",
      "training cost: 0.039980474991821585 validation cost0.03966528218509546: \n",
      "training mae: 0.21065805702852733 validation mae0.2113833342099599: \n",
      "Epochs: 356/500: \n",
      "training cost: 0.039972785164695136 validation cost0.03965857595980364: \n",
      "training mae: 0.21063885027777618 validation mae0.2113650621732653: \n",
      "Epochs: 357/500: \n",
      "training cost: 0.039965166826835284 validation cost0.039651933995990325: \n",
      "training mae: 0.21061984344296963 validation mae0.2113468687392662: \n",
      "Epochs: 358/500: \n",
      "training cost: 0.03995761901414899 validation cost0.03964535538949357: \n",
      "training mae: 0.21060096385237978 validation mae0.21132875341928445: \n",
      "Epochs: 359/500: \n",
      "training cost: 0.03995014077682493 validation cost0.039638839249907604: \n",
      "training mae: 0.21058223719140576 validation mae0.21131073196577177: \n",
      "Epochs: 360/500: \n",
      "training cost: 0.03994273117911226 validation cost0.03963238470036635: \n",
      "training mae: 0.2105636105771551 validation mae0.21129293494446436: \n",
      "Epochs: 361/500: \n",
      "training cost: 0.03993538929910267 validation cost0.03962599087733048: \n",
      "training mae: 0.21054516601060927 validation mae0.21127538479030677: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 362/500: \n",
      "training cost: 0.03992811422851619 validation cost0.03961965693037786: \n",
      "training mae: 0.2105269573389073 validation mae0.2112579371635064: \n",
      "Epochs: 363/500: \n",
      "training cost: 0.03992090507249035 validation cost0.039613382021997504: \n",
      "training mae: 0.21050892034375407 validation mae0.21124075796367825: \n",
      "Epochs: 364/500: \n",
      "training cost: 0.03991376094937261 validation cost0.03960716532738677: \n",
      "training mae: 0.21049116941660573 validation mae0.21122407025863746: \n",
      "Epochs: 365/500: \n",
      "training cost: 0.03990668099051637 validation cost0.03960100603425189: \n",
      "training mae: 0.21047359269208366 validation mae0.21120762443419444: \n",
      "Epochs: 366/500: \n",
      "training cost: 0.03989966434008003 validation cost0.03959490334261176: \n",
      "training mae: 0.21045614324341788 validation mae0.2111912495027286: \n",
      "Epochs: 367/500: \n",
      "training cost: 0.0398927101548294 validation cost0.03958885646460481: \n",
      "training mae: 0.21043887095730968 validation mae0.2111749518477206: \n",
      "Epochs: 368/500: \n",
      "training cost: 0.039885817603943184 validation cost0.039582864624299115: \n",
      "training mae: 0.21042184088538812 validation mae0.21115895932862985: \n",
      "Epochs: 369/500: \n",
      "training cost: 0.0398789858688217 validation cost0.039576927057505484: \n",
      "training mae: 0.21040502959241855 validation mae0.21114318547893202: \n",
      "Epochs: 370/500: \n",
      "training cost: 0.03987221414289854 validation cost0.039571043011593594: \n",
      "training mae: 0.21038834802732725 validation mae0.2111277494650743: \n",
      "Epochs: 371/500: \n",
      "training cost: 0.03986550163145531 validation cost0.039565211745311135: \n",
      "training mae: 0.2103719260612158 validation mae0.21111242388007145: \n",
      "Epochs: 372/500: \n",
      "training cost: 0.03985884755143928 validation cost0.03955943252860578: \n",
      "training mae: 0.21035573141613736 validation mae0.2110973117769643: \n",
      "Epochs: 373/500: \n",
      "training cost: 0.03985225113128402 validation cost0.03955370464245015: \n",
      "training mae: 0.21033981617541994 validation mae0.2110823185874517: \n",
      "Epochs: 374/500: \n",
      "training cost: 0.03984571161073283 validation cost0.039548027378669484: \n",
      "training mae: 0.21032407398029673 validation mae0.21106739181666506: \n",
      "Epochs: 375/500: \n",
      "training cost: 0.03983922824066503 validation cost0.0395424000397721: \n",
      "training mae: 0.21030853153457496 validation mae0.21105266155911478: \n",
      "Epochs: 376/500: \n",
      "training cost: 0.03983280028292496 validation cost0.0395368219387827: \n",
      "training mae: 0.21029314062751744 validation mae0.2110381032431768: \n",
      "Epochs: 377/500: \n",
      "training cost: 0.03982642701015378 validation cost0.039531292399078204: \n",
      "training mae: 0.2102779480666169 validation mae0.21102362550626344: \n",
      "Epochs: 378/500: \n",
      "training cost: 0.03982010770562386 validation cost0.03952581075422627: \n",
      "training mae: 0.21026293065205243 validation mae0.21100926622696484: \n",
      "Epochs: 379/500: \n",
      "training cost: 0.039813841663075916 validation cost0.0395203763478265: \n",
      "training mae: 0.21024803576534387 validation mae0.21099509258800356: \n",
      "Epochs: 380/500: \n",
      "training cost: 0.0398076281865586 validation cost0.03951498853335402: \n",
      "training mae: 0.21023338102766442 validation mae0.21098103563715273: \n",
      "Epochs: 381/500: \n",
      "training cost: 0.03980146659027075 validation cost0.03950964667400575: \n",
      "training mae: 0.2102188480894593 validation mae0.21096709762100113: \n",
      "Epochs: 382/500: \n",
      "training cost: 0.039795356198406066 validation cost0.039504350142548994: \n",
      "training mae: 0.2102043945357799 validation mae0.21095328347830739: \n",
      "Epochs: 383/500: \n",
      "training cost: 0.03978929634500033 validation cost0.039499098321172564: \n",
      "training mae: 0.2101901117441354 validation mae0.21093955043510193: \n",
      "Epochs: 384/500: \n",
      "training cost: 0.03978328637378094 validation cost0.0394938906013402: \n",
      "training mae: 0.21017598178578215 validation mae0.2109261658269789: \n",
      "Epochs: 385/500: \n",
      "training cost: 0.0397773256380189 validation cost0.03948872638364638: \n",
      "training mae: 0.21016203680415999 validation mae0.21091291190665704: \n",
      "Epochs: 386/500: \n",
      "training cost: 0.039771413500383185 validation cost0.03948360507767446: \n",
      "training mae: 0.21014840794237996 validation mae0.2108997847369544: \n",
      "Epochs: 387/500: \n",
      "training cost: 0.039765549332797315 validation cost0.03947852610185702: \n",
      "training mae: 0.21013494585876644 validation mae0.21088679263963814: \n",
      "Epochs: 388/500: \n",
      "training cost: 0.03975973251629827 validation cost0.03947348888333848: \n",
      "training mae: 0.21012170149849335 validation mae0.21087396275231582: \n",
      "Epochs: 389/500: \n",
      "training cost: 0.03975396244089753 validation cost0.03946849285783988: \n",
      "training mae: 0.2101085903232503 validation mae0.2108614534985159: \n",
      "Epochs: 390/500: \n",
      "training cost: 0.03974823850544455 validation cost0.03946353746952592: \n",
      "training mae: 0.21009562506141455 validation mae0.21084906852617216: \n",
      "Epochs: 391/500: \n",
      "training cost: 0.039742560117492054 validation cost0.0394586221708739: \n",
      "training mae: 0.21008278987088477 validation mae0.21083675609558739: \n",
      "Epochs: 392/500: \n",
      "training cost: 0.03973692669316371 validation cost0.039453746422545004: \n",
      "training mae: 0.21007001919133794 validation mae0.21082451234359745: \n",
      "Epochs: 393/500: \n",
      "training cost: 0.03973133765702384 validation cost0.03944890969325747: \n",
      "training mae: 0.2100573489660476 validation mae0.21081243004249656: \n",
      "Epochs: 394/500: \n",
      "training cost: 0.039725792441949 validation cost0.039444111459661806: \n",
      "training mae: 0.21004479668986567 validation mae0.21080054663436748: \n",
      "Epochs: 395/500: \n",
      "training cost: 0.03972029048900192 validation cost0.03943935120621805: \n",
      "training mae: 0.2100323134316931 validation mae0.2107887205784484: \n",
      "Epochs: 396/500: \n",
      "training cost: 0.03971483124730706 validation cost0.03943462842507492: \n",
      "training mae: 0.21001988651366008 validation mae0.21077704243335063: \n",
      "Epochs: 397/500: \n",
      "training cost: 0.03970941417392842 validation cost0.03942994261595088: \n",
      "training mae: 0.2100075277981589 validation mae0.21076541449820754: \n",
      "Epochs: 398/500: \n",
      "training cost: 0.03970403873374907 validation cost0.03942529328601716: \n",
      "training mae: 0.20999528028957415 validation mae0.21075385604842464: \n",
      "Epochs: 399/500: \n",
      "training cost: 0.039698704399352684 validation cost0.039420679949782586: \n",
      "training mae: 0.20998315811861598 validation mae0.21074247606894236: \n",
      "Epochs: 400/500: \n",
      "training cost: 0.03969341065090685 validation cost0.03941610212898021: \n",
      "training mae: 0.209971142669409 validation mae0.2107312502988617: \n",
      "Epochs: 401/500: \n",
      "training cost: 0.03968815697604832 validation cost0.03941155935245581: \n",
      "training mae: 0.20995918575072056 validation mae0.21072013982177798: \n",
      "Epochs: 402/500: \n",
      "training cost: 0.03968294286976994 validation cost0.03940705115605809: \n",
      "training mae: 0.2099473950777425 validation mae0.2107090681844212: \n",
      "Epochs: 403/500: \n",
      "training cost: 0.039677767834309416 validation cost0.03940257708253066: \n",
      "training mae: 0.2099357596747741 validation mae0.210698028660143: \n",
      "Epochs: 404/500: \n",
      "training cost: 0.039672631379039806 validation cost0.0393981366814057: \n",
      "training mae: 0.2099242566941107 validation mae0.2106870453045665: \n",
      "Epochs: 405/500: \n",
      "training cost: 0.039667533020361745 validation cost0.03939372950889937: \n",
      "training mae: 0.20991284361401444 validation mae0.21067617672703243: \n",
      "Epochs: 406/500: \n",
      "training cost: 0.039662472281597305 validation cost0.03938935512780872: \n",
      "training mae: 0.20990152509069632 validation mae0.21066542659900045: \n",
      "Epochs: 407/500: \n",
      "training cost: 0.03965744869288557 validation cost0.03938501310741044: \n",
      "training mae: 0.20989031980435052 validation mae0.21065475468344685: \n",
      "Epochs: 408/500: \n",
      "training cost: 0.039652461791079806 validation cost0.03938070302336102: \n",
      "training mae: 0.20987927890057406 validation mae0.21064413546999733: \n",
      "Epochs: 409/500: \n",
      "training cost: 0.03964751111964625 validation cost0.03937642445759863: \n",
      "training mae: 0.20986831257953695 validation mae0.2106336129791317: \n",
      "Epochs: 410/500: \n",
      "training cost: 0.03964259622856445 validation cost0.039372176998246446: \n",
      "training mae: 0.20985746540779796 validation mae0.2106231261142776: \n",
      "Epochs: 411/500: \n",
      "training cost: 0.03963771667422923 validation cost0.03936796023951754: \n",
      "training mae: 0.20984667687042213 validation mae0.21061268397829827: \n",
      "Epochs: 412/500: \n",
      "training cost: 0.03963287201935407 validation cost0.039363773781621314: \n",
      "training mae: 0.2098359737475675 validation mae0.21060232626333728: \n",
      "Epochs: 413/500: \n",
      "training cost: 0.03962806183287615 validation cost0.03935961723067131: \n",
      "training mae: 0.20982542874971966 validation mae0.21059200152388138: \n",
      "Epochs: 414/500: \n",
      "training cost: 0.039623285689862654 validation cost0.03935549019859455: \n",
      "training mae: 0.20981503278240105 validation mae0.2105817135512996: \n",
      "Epochs: 415/500: \n",
      "training cost: 0.03961854317141873 validation cost0.03935139230304229: \n",
      "training mae: 0.20980472908711986 validation mae0.2105714895742552: \n",
      "Epochs: 416/500: \n",
      "training cost: 0.039613833864596826 validation cost0.039347323167302176: \n",
      "training mae: 0.2097944636390957 validation mae0.2105613171191344: \n",
      "Epochs: 417/500: \n",
      "training cost: 0.039609157362307336 validation cost0.039343282420211706: \n",
      "training mae: 0.2097843284058769 validation mae0.21055123990846059: \n",
      "Epochs: 418/500: \n",
      "training cost: 0.03960451326323077 validation cost0.03933926969607321: \n",
      "training mae: 0.20977427838188564 validation mae0.2105413029712976: \n",
      "Epochs: 419/500: \n",
      "training cost: 0.039599901171731205 validation cost0.03933528463457003: \n",
      "training mae: 0.2097643228638651 validation mae0.21053146645033557: \n",
      "Epochs: 420/500: \n",
      "training cost: 0.03959532069777109 validation cost0.03933132688068403: \n",
      "training mae: 0.20975443473895852 validation mae0.21052170734061668: \n",
      "Epochs: 421/500: \n",
      "training cost: 0.0395907714568274 validation cost0.03932739608461454: \n",
      "training mae: 0.20974463087670586 validation mae0.2105119923149018: \n",
      "Epochs: 422/500: \n",
      "training cost: 0.03958625306980906 validation cost0.03932349190169832: \n",
      "training mae: 0.20973488634388068 validation mae0.21050239051988903: \n",
      "Epochs: 423/500: \n",
      "training cost: 0.03958176516297569 validation cost0.039319613992331026: \n",
      "training mae: 0.20972518211222627 validation mae0.2104929179706063: \n",
      "Epochs: 424/500: \n",
      "training cost: 0.039577307367857494 validation cost0.0393157620218898: \n",
      "training mae: 0.20971555669389183 validation mae0.21048357592648648: \n",
      "Epochs: 425/500: \n",
      "training cost: 0.039572879321176584 validation cost0.039311935660657: \n",
      "training mae: 0.2097059824359368 validation mae0.2104744097511908: \n",
      "Epochs: 426/500: \n",
      "training cost: 0.039568480664769305 validation cost0.039308134583745304: \n",
      "training mae: 0.20969645323745442 validation mae0.21046538245501492: \n",
      "Epochs: 427/500: \n",
      "training cost: 0.03956411104550992 validation cost0.03930435847102379: \n",
      "training mae: 0.20968701538141926 validation mae0.21045641347671384: \n",
      "Epochs: 428/500: \n",
      "training cost: 0.0395597701152354 validation cost0.03930060700704534: \n",
      "training mae: 0.20967767925269415 validation mae0.21044747060351485: \n",
      "Epochs: 429/500: \n",
      "training cost: 0.03955545753067137 validation cost0.03929687988097506: \n",
      "training mae: 0.20966841697675967 validation mae0.21043854720576718: \n",
      "Epochs: 430/500: \n",
      "training cost: 0.03955117295335926 validation cost0.03929317678651988: \n",
      "training mae: 0.20965930916822165 validation mae0.21042964321791: \n",
      "Epochs: 431/500: \n",
      "training cost: 0.03954691604958451 validation cost0.03928949742185926: \n",
      "training mae: 0.20965033536402267 validation mae0.21042079764937954: \n",
      "Epochs: 432/500: \n",
      "training cost: 0.03954268649030589 validation cost0.03928584148957691: \n",
      "training mae: 0.20964140510700474 validation mae0.21041199595861557: \n",
      "Epochs: 433/500: \n",
      "training cost: 0.03953848395108596 validation cost0.039282208696593664: \n",
      "training mae: 0.20963265544107534 validation mae0.21040322735659076: \n",
      "Epochs: 434/500: \n",
      "training cost: 0.03953430811202258 validation cost0.03927859875410135: \n",
      "training mae: 0.2096239549825221 validation mae0.2103947066142067: \n",
      "Epochs: 435/500: \n",
      "training cost: 0.039530158657681384 validation cost0.03927501137749769: \n",
      "training mae: 0.20961527142070183 validation mae0.21038635861801097: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 436/500: \n",
      "training cost: 0.03952603527702947 validation cost0.03927144628632224: \n",
      "training mae: 0.2096066925831857 validation mae0.2103780644607505: \n",
      "Epochs: 437/500: \n",
      "training cost: 0.03952193766336994 validation cost0.03926790320419332: \n",
      "training mae: 0.20959819082827164 validation mae0.2103698667933269: \n",
      "Epochs: 438/500: \n",
      "training cost: 0.03951786551427756 validation cost0.0392643818587459: \n",
      "training mae: 0.20958972270595946 validation mae0.21036172437022607: \n",
      "Epochs: 439/500: \n",
      "training cost: 0.0395138185315353 validation cost0.03926088198157052: \n",
      "training mae: 0.20958133151431363 validation mae0.2103535974362848: \n",
      "Epochs: 440/500: \n",
      "training cost: 0.039509796421071997 validation cost0.03925740330815304: \n",
      "training mae: 0.20957297627851354 validation mae0.21034551409414784: \n",
      "Epochs: 441/500: \n",
      "training cost: 0.03950579889290082 validation cost0.039253945577815516: \n",
      "training mae: 0.2095647125475938 validation mae0.21033754292623735: \n",
      "Epochs: 442/500: \n",
      "training cost: 0.03950182566105878 validation cost0.03925050853365776: \n",
      "training mae: 0.20955647327883317 validation mae0.2103296377812729: \n",
      "Epochs: 443/500: \n",
      "training cost: 0.039497876443547124 validation cost0.039247091922500026: \n",
      "training mae: 0.20954829017096 validation mae0.2103217466914125: \n",
      "Epochs: 444/500: \n",
      "training cost: 0.039493950962272664 validation cost0.03924369549482645: \n",
      "training mae: 0.20954022137340375 validation mae0.2103138696264873: \n",
      "Epochs: 445/500: \n",
      "training cost: 0.03949004894298998 validation cost0.039240319004729435: \n",
      "training mae: 0.20953220406052603 validation mae0.21030600655632775: \n",
      "Epochs: 446/500: \n",
      "training cost: 0.0394861701152445 validation cost0.03923696220985485: \n",
      "training mae: 0.2095242158873074 validation mae0.21029815745076413: \n",
      "Epochs: 447/500: \n",
      "training cost: 0.03948231421231655 validation cost0.039233624871348106: \n",
      "training mae: 0.20951626875505494 validation mae0.21029032227962827: \n",
      "Epochs: 448/500: \n",
      "training cost: 0.03947848097116607 validation cost0.039230306753801125: \n",
      "training mae: 0.20950839341512983 validation mae0.21028250101275453: \n",
      "Epochs: 449/500: \n",
      "training cost: 0.0394746701323784 validation cost0.039227007625200004: \n",
      "training mae: 0.20950061200368852 validation mae0.21027469361998083: \n",
      "Epochs: 450/500: \n",
      "training cost: 0.03947088144011068 validation cost0.03922372725687359: \n",
      "training mae: 0.20949288284920467 validation mae0.21026692797762447: \n",
      "Epochs: 451/500: \n",
      "training cost: 0.03946711464203924 validation cost0.03922046542344284: \n",
      "training mae: 0.20948521948104806 validation mae0.21025920651513677: \n",
      "Epochs: 452/500: \n",
      "training cost: 0.039463369489307676 validation cost0.03921722190277094: \n",
      "training mae: 0.20947759640193947 validation mae0.21025149840081905: \n",
      "Epochs: 453/500: \n",
      "training cost: 0.03945964573647578 validation cost0.03921399647591418: \n",
      "training mae: 0.20947000821944162 validation mae0.21024384114635927: \n",
      "Epochs: 454/500: \n",
      "training cost: 0.03945594314146926 validation cost0.03921078892707368: \n",
      "training mae: 0.2094624543813003 validation mae0.21023623582456746: \n",
      "Epochs: 455/500: \n",
      "training cost: 0.03945226146553014 validation cost0.03920759904354772: \n",
      "training mae: 0.2094549459035254 validation mae0.2102286749358032: \n",
      "Epochs: 456/500: \n",
      "training cost: 0.03944860047316803 validation cost0.039204426615684955: \n",
      "training mae: 0.20944744792435968 validation mae0.21022134996992417: \n",
      "Epochs: 457/500: \n",
      "training cost: 0.03944495993211205 validation cost0.03920127143683824: \n",
      "training mae: 0.20943996366493295 validation mae0.2102141121431269: \n",
      "Epochs: 458/500: \n",
      "training cost: 0.03944133961326352 validation cost0.039198133303319234: \n",
      "training mae: 0.20943252874772542 validation mae0.21020689447084967: \n",
      "Epochs: 459/500: \n",
      "training cost: 0.03943773929064938 validation cost0.03919501201435369: \n",
      "training mae: 0.20942512201556895 validation mae0.21019971550403552: \n",
      "Epochs: 460/500: \n",
      "training cost: 0.0394341587413763 validation cost0.039191907372037434: \n",
      "training mae: 0.2094178339233334 validation mae0.2101925711767506: \n",
      "Epochs: 461/500: \n",
      "training cost: 0.03943059774558548 validation cost0.039188819181292994: \n",
      "training mae: 0.20941056431743968 validation mae0.2101854371333442: \n",
      "Epochs: 462/500: \n",
      "training cost: 0.039427056086408195 validation cost0.03918574724982696: \n",
      "training mae: 0.20940330763700968 validation mae0.2101783309195221: \n",
      "Epochs: 463/500: \n",
      "training cost: 0.0394235335499219 validation cost0.03918269138808794: \n",
      "training mae: 0.20939606285047788 validation mae0.2101713004286833: \n",
      "Epochs: 464/500: \n",
      "training cost: 0.03942002992510713 validation cost0.03917965140922524: \n",
      "training mae: 0.20938882764908395 validation mae0.2101642894651867: \n",
      "Epochs: 465/500: \n",
      "training cost: 0.03941654500380498 validation cost0.03917662712904806: \n",
      "training mae: 0.20938160663147357 validation mae0.21015728809560655: \n",
      "Epochs: 466/500: \n",
      "training cost: 0.039413078580675207 validation cost0.03917361836598547: \n",
      "training mae: 0.20937441384691577 validation mae0.21015029631819607: \n",
      "Epochs: 467/500: \n",
      "training cost: 0.03940963045315507 validation cost0.03917062494104688: \n",
      "training mae: 0.2093672744307206 validation mae0.2101433177291705: \n",
      "Epochs: 468/500: \n",
      "training cost: 0.039406200421418694 validation cost0.03916764667778316: \n",
      "training mae: 0.20936022538863522 validation mae0.21013639338776624: \n",
      "Epochs: 469/500: \n",
      "training cost: 0.039402788288337064 validation cost0.039164683402248435: \n",
      "training mae: 0.2093532256395924 validation mae0.21012949818965296: \n",
      "Epochs: 470/500: \n",
      "training cost: 0.03939939385943869 validation cost0.039161734942962274: \n",
      "training mae: 0.20934627762319893 validation mae0.21012261197202314: \n",
      "Epochs: 471/500: \n",
      "training cost: 0.039396016942870794 validation cost0.03915880113087271: \n",
      "training mae: 0.20933938062283422 validation mae0.21011575624837261: \n",
      "Epochs: 472/500: \n",
      "training cost: 0.0393926573493611 validation cost0.03915588179931964: \n",
      "training mae: 0.20933253306753527 validation mae0.21010895213779174: \n",
      "Epochs: 473/500: \n",
      "training cost: 0.03938931489218027 validation cost0.039152976783998844: \n",
      "training mae: 0.209325718518238 validation mae0.21010225643157368: \n",
      "Epochs: 474/500: \n",
      "training cost: 0.03938598938710477 validation cost0.0391500859229266: \n",
      "training mae: 0.20931892628168847 validation mae0.21009560503293628: \n",
      "Epochs: 475/500: \n",
      "training cost: 0.039382680652380445 validation cost0.03914720905640479: \n",
      "training mae: 0.20931214347881236 validation mae0.21008896164716961: \n",
      "Epochs: 476/500: \n",
      "training cost: 0.039379388508686566 validation cost0.039144346026986555: \n",
      "training mae: 0.20930542357907422 validation mae0.21008232628243692: \n",
      "Epochs: 477/500: \n",
      "training cost: 0.03937611277910041 validation cost0.03914149667944249: \n",
      "training mae: 0.20929877675766168 validation mae0.21007570465511466: \n",
      "Epochs: 478/500: \n",
      "training cost: 0.03937285328906238 validation cost0.03913866086072736: \n",
      "training mae: 0.20929216257518743 validation mae0.21006915317238: \n",
      "Epochs: 479/500: \n",
      "training cost: 0.03936960986634172 validation cost0.039135838419947305: \n",
      "training mae: 0.20928561472816382 validation mae0.2100626185060814: \n",
      "Epochs: 480/500: \n",
      "training cost: 0.03936638234100268 validation cost0.03913302920832758: \n",
      "training mae: 0.20927907941009044 validation mae0.2100560913012295: \n",
      "Epochs: 481/500: \n",
      "training cost: 0.03936317054537116 validation cost0.039130233079180725: \n",
      "training mae: 0.2092726204849684 validation mae0.21004962428350765: \n",
      "Epochs: 482/500: \n",
      "training cost: 0.03935997431400195 validation cost0.03912744988787534: \n",
      "training mae: 0.2092662387957699 validation mae0.21004316599063735: \n",
      "Epochs: 483/500: \n",
      "training cost: 0.03935679348364639 validation cost0.03912467949180522: \n",
      "training mae: 0.20925988776661997 validation mae0.21003674215789944: \n",
      "Epochs: 484/500: \n",
      "training cost: 0.03935362789322053 validation cost0.039121921750359: \n",
      "training mae: 0.20925355875880255 validation mae0.21003035860447278: \n",
      "Epochs: 485/500: \n",
      "training cost: 0.039350477383773834 validation cost0.039119176524890366: \n",
      "training mae: 0.20924725194581842 validation mae0.21002412403354986: \n",
      "Epochs: 486/500: \n",
      "training cost: 0.039347341798458224 validation cost0.039116443678688516: \n",
      "training mae: 0.20924101174428522 validation mae0.21001794127934573: \n",
      "Epochs: 487/500: \n",
      "training cost: 0.039344220982497735 validation cost0.03911372307694925: \n",
      "training mae: 0.20923482377225566 validation mae0.2100118470378086: \n",
      "Epochs: 488/500: \n",
      "training cost: 0.03934111478315851 validation cost0.039111014586746484: \n",
      "training mae: 0.2092286417394265 validation mae0.2100058727593653: \n",
      "Epochs: 489/500: \n",
      "training cost: 0.039338023049719305 validation cost0.03910831807700407: \n",
      "training mae: 0.20922248349851055 validation mae0.20999994120724208: \n",
      "Epochs: 490/500: \n",
      "training cost: 0.03933494563344244 validation cost0.03910563341846821: \n",
      "training mae: 0.20921633738209625 validation mae0.20999405255575251: \n",
      "Epochs: 491/500: \n",
      "training cost: 0.03933188238754515 validation cost0.0391029604836802: \n",
      "training mae: 0.2092102341631556 validation mae0.20998822793035163: \n",
      "Epochs: 492/500: \n",
      "training cost: 0.03932883316717139 validation cost0.03910029914694957: \n",
      "training mae: 0.20920415594731434 validation mae0.20998242048596408: \n",
      "Epochs: 493/500: \n",
      "training cost: 0.039325797829364066 validation cost0.039097649284327754: \n",
      "training mae: 0.2091981034207783 validation mae0.20997662645722215: \n",
      "Epochs: 494/500: \n",
      "training cost: 0.03932277623303767 validation cost0.03909501077358203: \n",
      "training mae: 0.20919207420092456 validation mae0.20997083659233537: \n",
      "Epochs: 495/500: \n",
      "training cost: 0.03931976823895134 validation cost0.03909238349416991: \n",
      "training mae: 0.20918607948035378 validation mae0.20996507041156093: \n",
      "Epochs: 496/500: \n",
      "training cost: 0.039316773709682284 validation cost0.039089767327213955: \n",
      "training mae: 0.20918012938770456 validation mae0.20995934340758265: \n",
      "Epochs: 497/500: \n",
      "training cost: 0.03931379250959966 validation cost0.039087162155476904: \n",
      "training mae: 0.20917418584512779 validation mae0.20995364976259026: \n",
      "Epochs: 498/500: \n",
      "training cost: 0.03931082450483882 validation cost0.03908456786333728: \n",
      "training mae: 0.20916824616407131 validation mae0.2099479608599713: \n",
      "Epochs: 499/500: \n",
      "training cost: 0.039307869563275914 validation cost0.03908198433676524: \n",
      "training mae: 0.20916231036964433 validation mae0.20994228104907994: \n",
      "Epochs: 500/500: \n",
      "training cost: 0.0393049275545029 validation cost0.039079411463298915: \n",
      "training mae: 0.20915637848668364 validation mae0.20993662026690252: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_regression_model(X_train, y_train, X_val, y_val, 0.4, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean of each column\n",
    "mean_columns = mean(df.T, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtracte column means\n",
    "substract_mean = df - mean_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariance matrix\n",
    "convariance = cov(substract_mean.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigendecomposition\n",
    "values, vectors = eig(convariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "pca = vectors.T.dot(substract_mean.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.20574103e+05 -2.74849178e+04  1.82113759e+04 ... -2.76123887e-17\n",
      "  -2.57737839e-17  8.08129652e-17]\n",
      " [ 9.31201173e+05 -2.06478606e+04  1.32929858e+04 ... -2.41429417e-17\n",
      "  -2.40390604e-17  8.42824121e-17]\n",
      " [ 8.58848126e+05 -6.10616623e+04  4.88175260e+04 ... -6.23068582e-17\n",
      "  -2.92432308e-17  7.56087947e-17]\n",
      " ...\n",
      " [ 9.78457755e+05  4.55609078e+03 -1.07378088e+04 ... -1.65565256e-15\n",
      "  -1.13450490e-14 -7.08391379e-16]\n",
      " [ 9.75464533e+05  5.82265452e+03 -1.01408362e+04 ... -1.64871367e-15\n",
      "  -1.13450490e-14 -7.06656656e-16]\n",
      " [ 9.73704528e+05  7.10924767e+03 -1.12035071e+04 ... -1.67299980e-15\n",
      "  -1.13467837e-14 -7.04921932e-16]]\n"
     ]
    }
   ],
   "source": [
    "print(pca.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
